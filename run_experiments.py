#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨åŒ–å®éªŒè¿è¡Œå™¨
åŸºäºé…ç½®æ–‡ä»¶è¿è¡Œå¤šç»„RouteNetå®éªŒ
"""

import yaml
import os
import sys
import subprocess
import argparse
import time
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
import json

class ExperimentRunner:
    """å®éªŒè¿è¡Œå™¨"""
    
    def __init__(self, config_file="experiment_config.yaml"):
        """åˆå§‹åŒ–å®éªŒè¿è¡Œå™¨"""
        self.config_file = config_file
        self.config = self.load_config()
        self.results = {}
        
    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not os.path.exists(self.config_file):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨")
        
        with open(self.config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # å¦‚æœé…ç½®æ–‡ä»¶åŒ…å« model_configsï¼Œè‡ªåŠ¨ç”Ÿæˆ models
        if 'model_configs' in config:
            config = self._generate_models_from_configs(config)
        
        print(f"âœ… å·²åŠ è½½é…ç½®æ–‡ä»¶: {self.config_file}")
        print(f"ğŸ“‹ å‘ç° {len(config['models'])} ä¸ªæ¨¡å‹é…ç½®")
        print(f"ğŸ§ª å‘ç° {len(config['experiments'])} ç§å®éªŒç±»å‹")
        
        return config
    
    def _generate_models_from_configs(self, config):
        """åŸºäº model_configs è‡ªåŠ¨ç”Ÿæˆ models é…ç½®"""
        print("ğŸ”§ æ£€æµ‹åˆ° model_configsï¼Œè‡ªåŠ¨ç”Ÿæˆæ¨¡å‹é…ç½®...")
        
        model_configs = config.get('model_configs', [])
        
        generated_models = {}
        
        for model_config in model_configs:
            if not model_config.get('enabled', True):
                # å…¼å®¹æ—  physics å­—æ®µçš„é…ç½®
                physics = model_config.get('physics', 'none')
                print(f"â­ï¸  è·³è¿‡ç¦ç”¨çš„é…ç½®: {model_config['type']}_{physics}")
                continue
            # ä»…ä¿ç•™ä¸å«ç‰©ç†çº¦æŸçš„æ¨¡å‹
            physics = model_config.get('physics', 'none')
            if physics != 'none':
                print(f"â­ï¸  è·³è¿‡å«ç‰©ç†çº¦æŸçš„é…ç½®: {model_config['type']}_{physics}")
                continue

            # åŸºäº KAN åŸºå‡½æ•°å‘½åï¼ˆæ”¯æŒ bsplineï¼‰
            kan_basis = model_config.get('kan_basis')
            if model_config['type'] in ['kan', 'kan_bspline'] and kan_basis == 'bspline':
                model_name = 'kan_bspline'
            else:
                model_name = f"{model_config['type']}_none"

            # ç”Ÿæˆæ¨¡å‹é…ç½®
            model_def = {
                'model_type': model_config['type'],
                'physics_type': 'none',
                'lambda_physics': 0.0,
                'delay_model_dir': model_name,
                'use_kan': model_config['type'] in ['kan', 'kan_bspline'],
            }

            # é€ä¼  KAN åŸºå‡½æ•°é…ç½®ï¼ˆå¦‚æœæœ‰ï¼‰
            if kan_basis:
                model_def['kan_basis'] = kan_basis
            if 'kan_grid_size' in model_config:
                model_def['kan_grid_size'] = model_config.get('kan_grid_size')
            if 'kan_spline_order' in model_config:
                model_def['kan_spline_order'] = model_config.get('kan_spline_order')

            generated_models[model_name] = model_def
            print(f"âœ… ç”Ÿæˆæ¨¡å‹é…ç½®: {model_name}")
        
        # æ›´æ–°é…ç½®
        config['models'] = generated_models
        print(f"ğŸ¯ æ€»å…±ç”Ÿæˆ {len(generated_models)} ä¸ªæ¨¡å‹é…ç½®")
        
        return config
    
    def get_full_model_path(self, model_config):
        """è·å–å®Œæ•´çš„æ¨¡å‹è·¯å¾„"""
        models_base_dir = self.config['global_settings']['models_base_dir']
        delay_model_dir = model_config['delay_model_dir']
        return os.path.join(models_base_dir, delay_model_dir)
    
    def validate_model_paths(self, selected_models=None):
        """éªŒè¯æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼Œè¿”å›å­˜åœ¨çš„æ¨¡å‹å’Œç¼ºå¤±çš„æ¨¡å‹"""
        missing_models = []
        existing_models = {}
        
        # å¦‚æœæŒ‡å®šäº†é€‰ä¸­çš„æ¨¡å‹ï¼ŒåªéªŒè¯è¿™äº›æ¨¡å‹
        if selected_models:
            models_to_validate = {k: v for k, v in self.config['models'].items() if k in selected_models}
            validation_scope = f"é€‰ä¸­çš„ {len(models_to_validate)} ä¸ªæ¨¡å‹"
        else:
            models_to_validate = self.config['models']
            validation_scope = f"æ‰€æœ‰ {len(models_to_validate)} ä¸ªæ¨¡å‹"
        
        print(f"ğŸ” æ­£åœ¨éªŒè¯{validation_scope}çš„è·¯å¾„...")
        
        for model_name, model_config in models_to_validate.items():
            model_dir = self.get_full_model_path(model_config)
            if not os.path.exists(model_dir):
                missing_models.append(f"{model_name}: {model_dir}")
            else:
                existing_models[model_name] = model_config
        
        # æŠ¥å‘ŠéªŒè¯ç»“æœ
        print(f"âœ… å‘ç° {len(existing_models)} ä¸ªå¯ç”¨æ¨¡å‹")
        if missing_models:
            print(f"âš ï¸  ä»¥ä¸‹ {len(missing_models)} ä¸ªæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨:")
            for missing in missing_models:
                print(f"   - {missing}")
            print(f"ğŸš€ å°†ç»§ç»­è¿è¡Œå¯ç”¨çš„ {len(existing_models)} ä¸ªæ¨¡å‹")
        
        return existing_models, missing_models
    
    def build_command(self, experiment_type, model_name, model_config):
        """æ„å»ºå®éªŒå‘½ä»¤"""
        exp_config = self.config['experiments'][experiment_type]
        global_settings = self.config['global_settings']
        
        # åŸºç¡€å‘½ä»¤
        script_path = exp_config['script']
        cmd = ["python", script_path]
        
        # è¾“å‡ºç›®å½•
        output_dir = os.path.join(
            global_settings['base_output_dir'],
            model_name,
            experiment_type
        )
        
        # è·å–å®Œæ•´æ¨¡å‹è·¯å¾„
        full_model_path = self.get_full_model_path(model_config)
        
        # æ„å»ºå‚æ•°
        if experiment_type == "evaluate":
            cmd.extend([
                "--delay_model_dir", full_model_path,
                "--nsfnet_test_dir", global_settings['nsfnet_test_dir'],
                "--gbn_test_dir", global_settings['gbn_test_dir'],
                "--output_dir", output_dir,
                "--batch_size", str(global_settings['batch_size']),
                "--num_samples", str(global_settings['num_samples'])
            ])
            if model_config['use_kan']:
                cmd.append("--kan")
                # é€ä¼  KAN åŸºå‡½æ•°é…ç½®
                if model_config.get('kan_basis') == 'bspline':
                    cmd.extend(["--kan_basis", "bspline"])
                    if model_config.get('kan_grid_size') is not None:
                        cmd.extend(["--kan_grid_size", str(model_config['kan_grid_size'])])
                    if model_config.get('kan_spline_order') is not None:
                        cmd.extend(["--kan_spline_order", str(model_config['kan_spline_order'])])

        elif experiment_type == "numerical":
            cmd.extend([
                "--model_dir", full_model_path,
                "--nsfnet_test_dir", global_settings['nsfnet_test_dir'],
                "--gbn_test_dir", global_settings['gbn_test_dir'],
                "--output_dir", output_dir,
                "--batch_size", str(global_settings['batch_size']),
                "--num_samples", str(global_settings['num_samples'])
            ])
            if model_config['use_kan']:
                cmd.append("--kan")
                if model_config.get('kan_basis') == 'bspline':
                    cmd.extend(["--kan_basis", "bspline"])
                    if model_config.get('kan_grid_size') is not None:
                        cmd.extend(["--kan_grid_size", str(model_config['kan_grid_size'])])
                    if model_config.get('kan_spline_order') is not None:
                        cmd.extend(["--kan_spline_order", str(model_config['kan_spline_order'])])
        
        return cmd, output_dir
    
    def run_single_experiment(self, experiment_type, model_name, model_config):
        """è¿è¡Œå•ä¸ªå®éªŒ"""
        try:
            cmd, output_dir = self.build_command(experiment_type, model_name, model_config)
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            print(f"ğŸš€ å¼€å§‹å®éªŒ: {model_name} - {experiment_type}")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
            print(f"âš¡ å‘½ä»¤: {' '.join(cmd)}")
            
            # è¿è¡Œå®éªŒ
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=os.getcwd()
            )
            
            # è®¡ç®—è¿è¡Œæ—¶é—´
            duration = time.time() - start_time
            
            # ä¿å­˜ç»“æœ
            experiment_result = {
                'model_name': model_name,
                'experiment_type': experiment_type,
                'command': ' '.join(cmd),
                'output_dir': output_dir,
                'duration': duration,
                'return_code': result.returncode,
                'stdout_lines': result.stdout.split('\n') if result.stdout else [],
                'stderr_lines': result.stderr.split('\n') if result.stderr else [],
                'timestamp': datetime.now().isoformat()
            }
            
            if result.returncode == 0:
                print(f"âœ… å®éªŒæˆåŠŸ: {model_name} - {experiment_type} (è€—æ—¶: {duration:.1f}s)")
            else:
                print(f"âŒ å®éªŒå¤±è´¥: {model_name} - {experiment_type}")
                print(f"ğŸ’¬ é”™è¯¯ä¿¡æ¯: {result.stderr}")
                
            # ä¿å­˜å®éªŒæ—¥å¿—
            log_file = os.path.join(output_dir, "experiment_log.json")
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(experiment_result, f, indent=2, ensure_ascii=False)
            
            # ä¿å­˜ä¸€ä¸ªæ›´æ˜“è¯»çš„æ–‡æœ¬æ—¥å¿—
            readable_log_file = os.path.join(output_dir, "experiment_log.txt")
            with open(readable_log_file, 'w', encoding='utf-8') as f:
                f.write(f"å®éªŒ: {model_name} - {experiment_type}\n")
                f.write(f"{'='*60}\n")
                f.write(f"å¼€å§‹æ—¶é—´: {experiment_result['timestamp']}\n")
                f.write(f"è¿è¡Œæ—¶é—´: {duration:.2f} ç§’\n")
                f.write(f"è¿”å›ç : {result.returncode}\n")
                f.write(f"å‘½ä»¤: {' '.join(cmd)}\n\n")
                
                f.write("æ ‡å‡†è¾“å‡º:\n")
                f.write("-" * 40 + "\n")
                f.write(result.stdout if result.stdout else "æ— è¾“å‡º\n")
                f.write("\n")
                
                if result.stderr:
                    f.write("é”™è¯¯è¾“å‡º:\n")
                    f.write("-" * 40 + "\n")
                    f.write(result.stderr)
                    f.write("\n")
            
            return experiment_result
            
        except Exception as e:
            error_result = {
                'model_name': model_name,
                'experiment_type': experiment_type,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            print(f"ğŸ’¥ å®éªŒå¼‚å¸¸: {model_name} - {experiment_type}: {e}")
            return error_result
    
    def run_experiments(self, selected_models=None, selected_experiments=None, parallel=False, max_workers=4):
        """è¿è¡Œå®éªŒ"""
        # éªŒè¯æ¨¡å‹è·¯å¾„ï¼Œè·å–å¯ç”¨çš„æ¨¡å‹
        existing_models, missing_models = self.validate_model_paths(selected_models)
        
        if not existing_models:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œæ— æ³•è¿è¡Œå®éªŒ")
            return
        
        models_to_run = existing_models
        
        # ç­›é€‰å®éªŒç±»å‹
        if selected_experiments:
            experiments_to_run = [exp for exp in selected_experiments if exp in self.config['experiments']]
        else:
            experiments_to_run = list(self.config['experiments'].keys())
        
        print(f"\nğŸ¯ å‡†å¤‡è¿è¡Œå®éªŒ:")
        print(f"ğŸ“Š æ¨¡å‹æ•°é‡: {len(models_to_run)}")
        print(f"ğŸ§ª å®éªŒç±»å‹: {experiments_to_run}")
        print(f"ğŸ”¢ æ€»å®éªŒæ•°: {len(models_to_run) * len(experiments_to_run)}")
        print(f"âš¡ å¹¶è¡Œæ‰§è¡Œ: {'æ˜¯' if parallel else 'å¦'}")
        
        # ç¡®è®¤ç»§ç»­
        response = input("\nç¡®è®¤å¼€å§‹å®éªŒ? (y/N): ")
        if response.lower() != 'y':
            print("å–æ¶ˆå®éªŒ")
            return
        
        # è®°å½•æ‰€æœ‰å®éªŒä»»åŠ¡
        all_tasks = []
        for model_name, model_config in models_to_run.items():
            for experiment_type in experiments_to_run:
                all_tasks.append((experiment_type, model_name, model_config))
        
        # è¿è¡Œå®éªŒ
        start_time = time.time()
        
        if parallel and len(all_tasks) > 1:
            # å¹¶è¡Œè¿è¡Œ
            print(f"\nğŸ”„ ä½¿ç”¨ {max_workers} ä¸ªå¹¶è¡Œå·¥ä½œè¿›ç¨‹")
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_task = {
                    executor.submit(self.run_single_experiment, exp_type, model_name, model_config): 
                    (exp_type, model_name) 
                    for exp_type, model_name, model_config in all_tasks
                }
                
                for future in as_completed(future_to_task):
                    exp_type, model_name = future_to_task[future]
                    try:
                        result = future.result()
                        self.results[f"{model_name}_{exp_type}"] = result
                    except Exception as e:
                        print(f"ğŸ’¥ ä»»åŠ¡å¼‚å¸¸ {model_name}_{exp_type}: {e}")
        else:
            # ä¸²è¡Œè¿è¡Œ
            print(f"\nğŸ”„ ä¸²è¡Œè¿è¡Œå®éªŒ")
            for i, (exp_type, model_name, model_config) in enumerate(all_tasks, 1):
                print(f"\nğŸ“Š è¿›åº¦: {i}/{len(all_tasks)}")
                result = self.run_single_experiment(exp_type, model_name, model_config)
                self.results[f"{model_name}_{exp_type}"] = result
        
        # æ€»ç»“
        total_time = time.time() - start_time
        successful = sum(1 for r in self.results.values() if r.get('return_code') == 0)
        failed = len(self.results) - successful
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š å®éªŒå®Œæˆæ€»ç»“")
        print(f"{'='*60}")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f} ç§’")
        print(f"âœ… æˆåŠŸ: {successful} ä¸ª")
        print(f"âŒ å¤±è´¥: {failed} ä¸ª")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {self.config['global_settings']['base_output_dir']}")
        
        # ä¿å­˜å®éªŒæ€»ç»“
        summary_dir = os.path.join(self.config['global_settings']['base_output_dir'], "summary")
        os.makedirs(summary_dir, exist_ok=True)
        
        summary_file = os.path.join(summary_dir, f"experiment_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump({
                'total_experiments': len(all_tasks),
                'successful': successful,
                'failed': failed,
                'total_time': total_time,
                'results': self.results,
                'config': self.config_file
            }, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ è¯¦ç»†æ€»ç»“ä¿å­˜åœ¨: {summary_file}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è‡ªåŠ¨åŒ–RouteNetå®éªŒè¿è¡Œå™¨')
    parser.add_argument('--config', default='experiment_config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--models', nargs='+', help='æŒ‡å®šè¦è¿è¡Œçš„æ¨¡å‹ (é»˜è®¤å…¨éƒ¨)')
    parser.add_argument('--experiments', nargs='+', 
                       choices=['evaluate', 'gradient', 'numerical'],
                       help='æŒ‡å®šè¦è¿è¡Œçš„å®éªŒç±»å‹ (é»˜è®¤å…¨éƒ¨)')
    parser.add_argument('--parallel', action='store_true', help='å¹¶è¡Œè¿è¡Œå®éªŒ')
    parser.add_argument('--max_workers', type=int, default=4, help='æœ€å¤§å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°')
    parser.add_argument('--validate_only', action='store_true', help='ä»…éªŒè¯é…ç½®ï¼Œä¸è¿è¡Œå®éªŒ')
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–è¿è¡Œå™¨
        runner = ExperimentRunner(args.config)
        
        if args.validate_only:
            # ä»…éªŒè¯é…ç½®
            existing_models, missing_models = runner.validate_model_paths(selected_models=args.models)
            if missing_models:
                print("âš ï¸  å‘ç°ç¼ºå¤±çš„æ¨¡å‹ï¼Œä½†æœ‰å¯ç”¨æ¨¡å‹å¯ä»¥è¿è¡Œ")
            else:
                print("âœ… æ‰€æœ‰æ¨¡å‹è·¯å¾„éªŒè¯é€šè¿‡")
            return 0
        
        # è¿è¡Œå®éªŒ
        runner.run_experiments(
            selected_models=args.models,
            selected_experiments=args.experiments,
            parallel=args.parallel,
            max_workers=args.max_workers
        )
        
        return 0
        
    except Exception as e:
        print(f"ğŸ’¥ è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == '__main__':
    sys.exit(main())
