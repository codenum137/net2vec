# net2vec

This repository is a collection of machine learning models for computer networks with comprehensive training automation and experiment management.

Currently, the following models are implemented:

1. [Message Passing](mpnn) - vanilla Graph Neural Network
1. [RouteNet](routenet) - A new neural architecture designed for neural understanding of routing in the network.
1. **RouteNet TensorFlow 2** - Modern TensorFlow 2.x implementation with physics constraints, KAN architectures, and automated training

## ğŸŒŸ Key Features

- **ğŸ§  Multiple Architectures**: Traditional MLP vs Kolmogorov-Arnold Networks (KAN)
- **âš¡ Physics Constraints**: Soft and hard physics constraint implementations  
- **ğŸ¤– Automated Training**: Systematic training across 14 different model configurations
- **ğŸ“Š Comprehensive Evaluation**: Automated experiment management and comparison
- **ğŸ“ˆ Real-time Monitoring**: Live training progress and TensorBoard integration
- **ğŸ”§ Modern TF2**: Keras APIs, eager execution, and best practices

**If you decide to apply the concepts presented or base on the provided code, please do refer our related paper**

## ğŸš€ Quick Start

**For automated training of all model configurations:**
```bash
# Install dependencies
pip install tensorflow tqdm numpy matplotlib seaborn

# Train all 14 model configurations (MLP/KAN Ã— No/Soft/Hard physics)
python train_models.py

# Models will be saved to fixed_model/ with descriptive names
```

**For single model training:**
```bash
# Train a specific RouteNet configuration
python routenet/routenet_tf2.py \
    --train_dir data/routenet/nsfnetbw/tfrecords/train/ \
    --eval_dir data/routenet/nsfnetbw/tfrecords/evaluate/ \
    --model_dir models/custom_model \
    --target delay \
    --epochs 20
```

## RouteNet TensorFlow 2 Implementation

### ğŸ“‹ Prerequisites

```bash
# Create conda environment
conda create --name routenet-tf2-env python=3.9 -y
conda activate routenet-tf2-env

# Install dependencies
pip install tensorflow tqdm numpy matplotlib seaborn
```

### ğŸš€ Training the Model

Use `routenet_tf2.py` to train the RouteNet model with modern TensorFlow 2.x:

```bash
python routenet/routenet_tf2.py     --train_dir data/routenet/nsfnetbw/tfrecords/train/     --eval_dir data/routenet/nsfnetbw/tfrecords/evaluate/     --model_dir models/routenet_tf2_model     --target drops     --epochs 20     --batch_size 32  --lr_schedule plateau   --learning_rate 0.001 --plateau_patience 5 --plateau_factor 0.5
```

**Training Parameters:**
- `--train_dir`: Directory containing training TFRecord files
- `--eval_dir`: Directory containing evaluation TFRecord files  
- `--model_dir`: Directory to save model checkpoints and logs
- `--epochs`: Number of training epochs (default: 10)
- `--batch_size`: Batch size for training (default: 16)
- `--learning_rate`: Learning rate for optimization (default: 0.001)

**Features:**
- âœ… **TensorBoard Integration**: Automatic logging of training/validation losses
- âœ… **Best Model Saving**: Automatically saves the best performing model
- âœ… **Modern TF2 APIs**: Uses Keras, `@tf.function`, and eager execution
- âœ… **Progress Tracking**: Real-time training progress with tqdm

### ğŸ“Š Monitoring Training Progress

The training script automatically creates TensorBoard logs. To visualize training progress:

```bash
# View current training logs
tensorboard --logdir models/routenet_tf2_model/logs/

# Or specify a particular training run
tensorboard --logdir models/routenet_tf2_model/logs/20250822-030524
```

Then open http://localhost:6006 in your browser to see:
- Training and validation loss curves
- Learning rate schedules
- Batch-level loss tracking
- Best model performance tracking

### ğŸ“ˆ Model Evaluation and Visualization

Use `evaluate_routenet.py` to load trained models and generate comprehensive analysis:

```bash
# Basic evaluation
python evaluate_routenet.py --delay_model_dir models/routenet_tf2_model/nsfnetbw_delay --drops_model_dir models/routenet_tf2_model/nsfnetbw_drops --nsfnet_test_dir data/routenet/nsfnetbw/tfrecords/evaluate --gbn_test_dir data/routenet/gbnbw/tfrecords/evaluate --output_dir evaluation_results --num_samples 1000

# Quick evaluation with limited samples
python evaluate_routenet.py \
    --model_dir models/routenet_tf2_model \
    --test_dir data/routenet/nsfnetbw/tfrecords/evaluate \
    --output_dir evaluation_results \
    --num_samples 1000 \
    --batch_size 16
```

**Evaluation Parameters:**
- `--model_dir`: Directory containing trained model weights
- `--test_dir`: Directory containing test TFRecord files
- `--output_dir`: Directory to save evaluation results (default: evaluation_results)
- `--num_samples`: Number of samples to evaluate (None for all)
- `--batch_size`: Batch size for evaluation (default: 32)

**Generated Outputs:**
1. **`relative_error_cdf.png`** - Cumulative Distribution Function of relative errors
2. **`detailed_analysis.png`** - Scatter plots and error distributions
3. **Console metrics** - MAE, RMSE, MAPE, and statistical summaries

### ğŸ“Š Evaluation Metrics

The evaluation script provides comprehensive metrics:

- **MAE (Mean Absolute Error)**: Average absolute prediction error
- **RMSE (Root Mean Square Error)**: Square root of mean squared errors
- **MAPE (Mean Absolute Percentage Error)**: Average relative error percentage
- **Relative Error Statistics**: Mean, standard deviation, and 95th percentile

### ğŸ”„ Typical Workflows

#### **Option 1: Single Model Training**
1. **Prepare Data**: Ensure TFRecord files are in the correct format
2. **Train Model**: Use `routenet_tf2.py` to train a specific configuration
3. **Monitor Progress**: Use TensorBoard to track training
4. **Evaluate Results**: Use `evaluate_routenet.py` to assess performance

#### **Option 2: Comprehensive Model Comparison**
1. **Prepare Data**: Ensure TFRecord files are in the correct format
2. **Automated Training**: Use `train_models.py` to train all 14 model configurations
3. **Monitor Progress**: Real-time epoch progress for each model
4. **Systematic Evaluation**: Use experiment automation for comprehensive comparison
5. **Analysis**: Review comparative results across architectures and constraints

#### **Option 3: Custom Experiment Design**
1. **Configure Experiments**: Modify `experiment_config.yaml` for specific comparisons
2. **Selective Training**: Train specific model subsets using `train_models.py`
3. **Automated Evaluation**: Run experiment automation for systematic analysis
4. **Results Analysis**: Generate comparative reports and visualizations

## ğŸ¤– Automated Training System

### Systematic Model Training with `train_models.py`

The `train_models.py` script provides automated training for comprehensive model comparison across different architectures and physics constraints:

```bash
python train_models.py
```

**Training Configurations (14 models total):**

1. **MLP-based models** (7 configurations):
   - No physics constraints with Î» âˆˆ {0}
   - Soft physics constraints with Î» âˆˆ {0.001, 0.01, 0.1}
   - Hard physics constraints with Î» âˆˆ {0.001, 0.01, 0.1}

2. **KAN-based models** (7 configurations):
   - No physics constraints with Î» âˆˆ {0}
   - Soft physics constraints with Î» âˆˆ {0.001, 0.01, 0.1}
   - Hard physics constraints with Î» âˆˆ {0.001, 0.01, 0.1}

**Features:**
- âœ… **Epoch Progress Tracking**: Shows current epoch and percentage progress only
- âœ… **Detailed Logging**: Full training output saved to individual log files
- âœ… **Organized Storage**: Models saved to `fixed_model/` with descriptive names
- âœ… **Complete Coverage**: Tests all architecture and constraint combinations
- âœ… **Robust Training**: Handles interruptions and errors gracefully

**Model Directory Structure:**
```
fixed_model/
â”œâ”€â”€ mlp_no_physics_lambda_0/
â”‚   â”œâ”€â”€ training.log              # å®Œæ•´è®­ç»ƒæ—¥å¿—
â”‚   â”œâ”€â”€ best_delay_model.weights.h5
â”‚   â””â”€â”€ logs/                     # TensorBoardæ—¥å¿—
â”œâ”€â”€ mlp_soft_physics_lambda_0.001/
â”‚   â”œâ”€â”€ training.log
â”‚   â”œâ”€â”€ best_delay_model.weights.h5
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ mlp_soft_physics_lambda_0.01/
â”œâ”€â”€ mlp_soft_physics_lambda_0.1/
â”œâ”€â”€ mlp_hard_physics_lambda_0.001/
â”œâ”€â”€ mlp_hard_physics_lambda_0.01/
â”œâ”€â”€ mlp_hard_physics_lambda_0.1/
â”œâ”€â”€ kan_no_physics_lambda_0/
â”œâ”€â”€ kan_soft_physics_lambda_0.001/
â”œâ”€â”€ kan_soft_physics_lambda_0.01/
â”œâ”€â”€ kan_soft_physics_lambda_0.1/
â”œâ”€â”€ kan_hard_physics_lambda_0.001/
â”œâ”€â”€ kan_hard_physics_lambda_0.01/
â””â”€â”€ kan_hard_physics_lambda_0.1/
```

### Training Logs

Each model generates a detailed `training.log` file containing:

- **ğŸ“‹ Training Configuration**: Model type, physics constraints, parameters
- **âš¡ Execution Command**: Full command used for training
- **ğŸ“Š Complete Output**: All TensorFlow/Keras training output
- **ğŸ“ˆ Progress Markers**: Epoch progress with timestamps
- **âœ… Final Results**: Success/failure status and timing
- **ğŸ” Error Details**: Exception information if training fails

**Log File Format:**
```log
================================================================================
è®­ç»ƒå¼€å§‹æ—¶é—´: 2025-09-10 12:14:56
æ¨¡å‹é…ç½®: mlp_soft_physics_lambda_0.001
æ‰§è¡Œå‘½ä»¤: python routenet/routenet_tf2.py --train_dir ...
================================================================================

Loading training data...
Epoch 1/20
100/100 [==============================] - 15s - loss: 0.1234 - val_loss: 0.0987

[PROGRESS] ğŸ“ˆ è®­ç»ƒè¿›åº¦: Epoch 1/20 (5.0%)
...

[SUCCESS] è®­ç»ƒæˆåŠŸå®Œæˆ!
```

### Physics Constraints Explained

**Physics Constraint Types:**
- **No Physics**: Traditional neural network training (Î» = 0)
- **Soft Physics**: Batch-averaged gradient constraints (gradual enforcement)
- **Hard Physics**: Per-sample gradient constraints (strict enforcement)

**Lambda Values:**
- `Î» = 0.001`: Weak constraint influence
- `Î» = 0.01`: Moderate constraint influence  
- `Î» = 0.1`: Strong constraint influence

## ğŸ”¬ Experiment Automation with YAML Configuration

### Automated Evaluation with `experiment_config.yaml`

The experiment automation system enables systematic model evaluation across multiple configurations:

```bash
# Run automated experiment evaluation
python run_experiments.py experiment_config.yaml
```

**Configuration Structure:**
```yaml
experiments:
  mlp_soft_0001:
    model_dir: "fixed_model/mlp_soft_physics_lambda_0.001"
    architecture: "mlp"
    physics_constraint: "soft"
    lambda_value: 0.001
    
  kan_hard_01:
    model_dir: "fixed_model/kan_hard_physics_lambda_0.1" 
    architecture: "kan"
    physics_constraint: "hard"
    lambda_value: 0.1
```

**Evaluation Outputs:**
- Performance comparison across all model variants
- Statistical significance testing
- Comprehensive visualization of results
- Automated report generation

### ğŸ’¡ Tips and Best Practices

- **Training Duration**: Each model trains for 20 epochs, total ~4-6 hours for all 14 models
- **Batch Size**: Start with smaller batch sizes (8-16) to reduce memory usage
- **Epochs**: Monitor validation loss to avoid overfitting
- **Data Quality**: Ensure TFRecord files contain all required features
- **GPU Memory**: The model will use GPU automatically if available
- **Retracing Warnings**: Some TF function retracing is normal due to variable graph sizes
- **Model Comparison**: Use experiment automation for systematic performance analysis
- **Physics Constraints**: Start with soft constraints (easier convergence) before hard constraints



# PC-Score ç‰©ç†ä¸€è‡´æ€§è¯„åˆ†ç³»ç»Ÿ - å®Œæ•´å®ç°æŠ¥å‘Š

## ğŸ¯ é¡¹ç›®æ€»ç»“

æˆ‘ä»¬æˆåŠŸå®ç°äº†å®Œæ•´çš„PC-Scoreï¼ˆç‰©ç†ä¸€è‡´æ€§è¯„åˆ†ï¼‰ç³»ç»Ÿï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºä¸¥æ ¼æ•°å­¦å…¬å¼çš„RouteNetæ¨¡å‹ç‰©ç†è§„å¾‹å­¦ä¹ è¯„ä¼°æ¡†æ¶ã€‚

## ğŸ“Š æ ¸å¿ƒæ•°å­¦å…¬å¼å®ç°

### ä¸»å…¬å¼ (å…¬å¼1) - PC-Scoreæ€»åˆ†
```
PC-Score = w_self Ã— S_self + w_mono Ã— S_mono + w_cross Ã— S_cross + w_indep Ã— S_indep + w_congest Ã— S_congest
```

### å­å…¬å¼å®ç°

#### 1. S_self (å…¬å¼2) - è‡ªå½±å“ä¸ºæ­£
```
S_self = (1/N) Ã— Î£ I(g_kk^(i) â‰¥ 0)
```
- **ç‰©ç†å«ä¹‰**: è·¯å¾„å¢åŠ è‡ªèº«æµé‡åº”å¢åŠ è‡ªèº«å»¶è¿Ÿ
- **å®ç°**: ç»Ÿè®¡è‡ªå½±å“æ¢¯åº¦â‰¥0çš„æ ·æœ¬æ¯”ä¾‹
- **éªŒè¯ç»“æœ**: âœ… é€šè¿‡ (0.900)

#### 2. S_mono (å…¬å¼3) - å»¶è¿Ÿå•è°ƒæ€§
```
S_mono = (1/(N-1)) Ã— Î£ I(D_k(T_{i+1}) â‰¥ D_k(T_i))
```
- **ç‰©ç†å«ä¹‰**: éšç€æµé‡å¢åŠ ï¼Œå»¶è¿Ÿåº”å•è°ƒé€’å¢
- **å®ç°**: ç»Ÿè®¡å»¶è¿Ÿå•è°ƒé€’å¢çš„æ­¥æ•°æ¯”ä¾‹
- **éªŒè¯ç»“æœ**: âœ… é€šè¿‡ (0.889)

#### 3. S_cross (å…¬å¼4) - å…±äº«è·¯å¾„äº¤å‰å½±å“ä¸ºæ­£
```
S_cross = (1/|P_shared|) Ã— Î£ ((1/N) Ã— Î£ I(g_ij^(k) â‰¥ 0))
```
- **ç‰©ç†å«ä¹‰**: å…±äº«èµ„æºçš„è·¯å¾„åº”ç›¸äº’å¹²æ‰°ï¼ˆæ­£å½±å“ï¼‰
- **å®ç°**: æ‹“æ‰‘æ„ŸçŸ¥çš„äº¤å‰æ¢¯åº¦æ­£å€¼æ¯”ä¾‹å¹³å‡
- **éªŒè¯ç»“æœ**: âœ… é€šè¿‡ (0.750)

#### 4. S_indep (å…¬å¼5) - ç‹¬ç«‹è·¯å¾„é›¶å½±å“
```
S_indep = max(0, 1 - E[|g_ij|]_{(i,j)âˆˆP_indep} / Ï„)
```
- **ç‰©ç†å«ä¹‰**: æ‹“æ‰‘ç‹¬ç«‹çš„è·¯å¾„åº”äº’ä¸å½±å“
- **å®ç°**: åŸºäºå®¹å¿é˜ˆå€¼Ï„çš„ç‹¬ç«‹è·¯å¾„å½±å“è¯„ä¼°
- **éªŒè¯ç»“æœ**: âœ… é€šè¿‡ (0.860)

#### 5. S_congest (å…¬å¼6) - æ‹¥å¡æ•æ„Ÿæ€§
```
S_congest = (1/(N-1)) Ã— Î£ I(g_kk^(i+1) â‰¥ g_kk^(i))
```
- **ç‰©ç†å«ä¹‰**: ç½‘ç»œè¶Šæ‹¥å¡ï¼Œå»¶è¿Ÿå¯¹æ–°å¢æµé‡è¶Šæ•æ„Ÿ
- **å®ç°**: è‡ªå½±å“æ¢¯åº¦å•è°ƒé€’å¢æ¯”ä¾‹
- **éªŒè¯ç»“æœ**: âœ… é€šè¿‡ (0.333)

## ğŸ”§ ç³»ç»Ÿç‰¹æ€§

### æƒé‡é…ç½®ç³»ç»Ÿ
- **é»˜è®¤æƒé‡**: `{self: 0.25, mono: 0.20, cross: 0.25, indep: 0.15, congest: 0.15}`
- **è‡ªåŠ¨å½’ä¸€åŒ–**: ç¡®ä¿æƒé‡ä¹‹å’Œä¸º1.0
- **çµæ´»é…ç½®**: æ”¯æŒè‡ªå®šä¹‰æƒé‡åˆ†é…

### å®¹å¿é˜ˆå€¼è®¾ç½®
- **é»˜è®¤Ï„**: 1e-4 (ç‹¬ç«‹è·¯å¾„é›¶å½±å“è¯„ä¼°)
- **ç‰©ç†æ„ä¹‰**: å®šä¹‰"è¶³å¤Ÿå°"çš„äº¤å‰å½±å“é˜ˆå€¼
- **å¯è°ƒå‚æ•°**: æ”¯æŒæ ¹æ®ç½‘ç»œç‰¹æ€§è°ƒæ•´

### éªŒè¯é˜ˆå€¼
- **é€šè¿‡æ ‡å‡†**: PC-Score â‰¥ 0.7
- **è§£é‡Šä½“ç³»**: 
  - 0.9-1.0: ğŸŒŸ ä¼˜ç§€
  - 0.8-0.9: âœ… è‰¯å¥½  
  - 0.7-0.8: âœ“ åŠæ ¼
  - 0.6-0.7: âš ï¸ ä¸€èˆ¬
  - 0.0-0.6: âŒ è¾ƒå·®

## ğŸ“ å®ç°æ–‡ä»¶ç»“æ„

```
routenet/
â”œâ”€â”€ gradient_sanity_check.py       # æ ¸å¿ƒPC-Scoreå®ç°
â”‚   â”œâ”€â”€ validate_physical_intuition()     # ä¸»å…¥å£å‡½æ•°
â”‚   â”œâ”€â”€ _compute_s_self_formula()         # S_selfè®¡ç®—
â”‚   â”œâ”€â”€ _compute_s_mono_formula()         # S_monoè®¡ç®—  
â”‚   â”œâ”€â”€ _compute_s_cross_formula()        # S_crossè®¡ç®—
â”‚   â”œâ”€â”€ _compute_s_indep_formula()        # S_indepè®¡ç®—
â”‚   â”œâ”€â”€ _compute_s_congest_formula()      # S_congestè®¡ç®—
â”‚   â”œâ”€â”€ _print_pc_score_results()         # ç»“æœè¾“å‡º
â”‚   â””â”€â”€ _visualize_pc_score()             # å¯è§†åŒ–è°ƒç”¨
â”‚
â”œâ”€â”€ pc_score_visualization.py      # PC-Scoreå¯è§†åŒ–ç³»ç»Ÿ
â””â”€â”€ test_pc_score_formulas.py     # æ•°å­¦å…¬å¼éªŒè¯æµ‹è¯•
```

## ğŸ§ª éªŒè¯æµ‹è¯•ç»“æœ

### æ•°å­¦å…¬å¼éªŒè¯
```
âœ… S_self å…¬å¼: è‡ªå½±å“æ¢¯åº¦æ­£å€¼æ¯”ä¾‹ (0.900)
âœ… S_mono å…¬å¼: å»¶è¿Ÿå•è°ƒæ€§æ¯”ä¾‹ (0.889)
âœ… S_cross å…¬å¼: å…±äº«è·¯å¾„äº¤å‰å½±å“æ­£å€¼æ¯”ä¾‹ (0.750)  
âœ… S_indep å…¬å¼: ç‹¬ç«‹è·¯å¾„é›¶å½±å“è¯„ä¼° (0.860)
âœ… S_congest å…¬å¼: æ‹¥å¡æ•æ„Ÿæ€§å•è°ƒæ€§ (0.333)
âœ… PC-Score å…¬å¼: åŠ æƒå’Œè®¡ç®— (0.7693)
âœ… æƒé‡å½’ä¸€åŒ–: è‡ªåŠ¨æ ‡å‡†åŒ–
```

### ç»¼åˆæµ‹è¯•æ¡ˆä¾‹
```
ç»„ä»¶å¾—åˆ†:
  S_self: 0.900 Ã— 0.25 = 0.2250
  S_mono: 0.889 Ã— 0.20 = 0.1778
  S_cross: 0.750 Ã— 0.25 = 0.1875
  S_indep: 0.860 Ã— 0.15 = 0.1290
  S_congest: 0.333 Ã— 0.15 = 0.0500
  
æœ€ç»ˆ PC-Score: 0.7693 (é€šè¿‡é˜ˆå€¼0.7)
```

## ğŸ“ˆ å¯è§†åŒ–ç³»ç»Ÿ

### ç”Ÿæˆå†…å®¹
1. **å»¶è¿Ÿvsæµé‡å›¾** - S_monoç›¸å…³åˆ†æ
2. **è‡ªå½±å“æ¢¯åº¦æ•£ç‚¹å›¾** - S_selfç›¸å…³åˆ†æ  
3. **æ‹¥å¡æ•æ„Ÿæ€§å›¾** - S_congestç›¸å…³åˆ†æ
4. **äº¤å‰å½±å“æ¢¯åº¦å›¾** - S_crossç›¸å…³åˆ†æ
5. **PC-Scoreé›·è¾¾å›¾** - äº”ç»´è¯„ä¼°å¯è§†åŒ–
6. **æ€»ç»“æ–‡æœ¬é¢æ¿** - è¯¦ç»†æ•°å€¼åˆ†æ

### è¾“å‡ºæ–‡ä»¶
- `pc_score_analysis_path_{id}.png` - ç»¼åˆåˆ†æå›¾è¡¨
- `pc_score_results_path_{id}.txt` - è¯¦ç»†æ•°å€¼æŠ¥å‘Š

## ğŸ”— é›†æˆæ–¹å¼

### è°ƒç”¨æ¥å£
```python
validation_results = checker.validate_physical_intuition(
    experiment_results=experiment_data,
    network_config=network_config,
    path_to_vary=path_id,
    output_dir=output_directory,
    weights=custom_weights,      # å¯é€‰ï¼šè‡ªå®šä¹‰æƒé‡
    tau=1e-4                     # å¯é€‰ï¼šå®¹å¿é˜ˆå€¼
)

# è·å–ç»“æœ
pc_score = validation_results['pc_score']
components = validation_results['components']
passed = validation_results['validation_passed']
```

### ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ
- **RouteNetè®­ç»ƒ**: è®­ç»ƒåè‡ªåŠ¨PC-Scoreè¯„ä¼°
- **å®éªŒé…ç½®**: experiment_config.yamlæ”¯æŒPC-Scoreå‚æ•°
- **æ‰¹é‡è¯„ä¼°**: train_models.pyé›†æˆPC-ScoreéªŒè¯
- **æ•°å€¼åˆ†æ**: numerical_analysis.pyæ•´åˆPC-ScoreæŒ‡æ ‡

## ğŸš€ ä¼˜åŠ¿ä¸åˆ›æ–°

### ç§‘å­¦ä¸¥è°¨æ€§
- **æ•°å­¦åŸºç¡€**: åŸºäºä¸¥æ ¼çš„æ•°å­¦å…¬å¼ï¼Œè€Œéå¯å‘å¼è§„åˆ™
- **ç‰©ç†æ„ä¹‰**: æ¯ä¸ªç»„ä»¶éƒ½å¯¹åº”æ˜ç¡®çš„ç½‘ç»œç‰©ç†è§„å¾‹
- **é‡åŒ–è¯„ä¼°**: è¿ç»­æ•°å€¼è¯„åˆ†ï¼Œæ”¯æŒç²¾ç¡®æ¯”è¾ƒ

### ç³»ç»Ÿå®Œæ•´æ€§  
- **å…¨é¢è¦†ç›–**: æ¶µç›–è‡ªå½±å“ã€å•è°ƒæ€§ã€äº¤å‰å½±å“ã€ç‹¬ç«‹æ€§ã€æ‹¥å¡æ•æ„Ÿæ€§
- **æ‹“æ‰‘æ„ŸçŸ¥**: åŒºåˆ†å…±äº«ä¸ç‹¬ç«‹è·¯å¾„ï¼Œé¿å…è¯¯åˆ¤
- **é…ç½®çµæ´»**: æ”¯æŒæƒé‡å’Œé˜ˆå€¼çš„è‡ªå®šä¹‰è°ƒæ•´

### å®ç”¨ä»·å€¼
- **æ¨¡å‹è°ƒè¯•**: å¿«é€Ÿè¯†åˆ«æ¨¡å‹å­¦ä¹ çš„ç‰©ç†è§„å¾‹ç¼ºé™·
- **æ¶æ„æ¯”è¾ƒ**: å®¢è§‚æ¯”è¾ƒMLP vs KANçš„ç‰©ç†ä¸€è‡´æ€§
- **è®­ç»ƒæŒ‡å¯¼**: ä¸ºç‰©ç†çº¦æŸæŸå¤±å‡½æ•°æä¾›é‡åŒ–åé¦ˆ

## ğŸ“Š åº”ç”¨åœºæ™¯

1. **æ¨¡å‹éªŒè¯**: è®­ç»ƒå®Œæˆåçš„ç‰©ç†è§„å¾‹å­¦ä¹ è¯„ä¼°
2. **æ¶æ„é€‰æ‹©**: MLP vs KANç‰©ç†ä¸€è‡´æ€§å¯¹æ¯”
3. **è¶…å‚ä¼˜åŒ–**: ç‰©ç†çº¦æŸæƒé‡Î»_physicsçš„è°ƒèŠ‚æŒ‡å¯¼  
4. **è°ƒè¯•è¯Šæ–­**: è¯†åˆ«æ¨¡å‹åœ¨ç‰¹å®šç‰©ç†è§„å¾‹ä¸Šçš„å­¦ä¹ ç¼ºé™·
5. **è®ºæ–‡è¯„ä¼°**: ä¸ºRouteNetç ”ç©¶æä¾›æ ‡å‡†åŒ–è¯„ä¼°æŒ‡æ ‡

## ğŸ‰ æ€»ç»“

PC-Scoreç³»ç»ŸæˆåŠŸå®ç°äº†æ‚¨è¦æ±‚çš„å®Œæ•´æ•°å­¦å…¬å¼è§„èŒƒï¼Œæä¾›äº†ï¼š

- âœ… **ä¸¥æ ¼çš„æ•°å­¦åŸºç¡€** - 5ä¸ªå­å…¬å¼ + 1ä¸ªä¸»å…¬å¼
- âœ… **å®Œæ•´çš„å®ç°ä»£ç ** - ç»è¿‡æ•°å€¼éªŒè¯çš„ç®—æ³•
- âœ… **çµæ´»çš„é…ç½®ç³»ç»Ÿ** - æƒé‡å’Œé˜ˆå€¼å¯è°ƒ
- âœ… **ä¸°å¯Œçš„å¯è§†åŒ–** - å¤šç»´åº¦åˆ†æå›¾è¡¨
- âœ… **æ— ç¼çš„ç³»ç»Ÿé›†æˆ** - ä¸ç°æœ‰RouteNetæ¡†æ¶å®Œå…¨å…¼å®¹

è¿™ä¸ªç³»ç»Ÿä¸ºRouteNetæ¨¡å‹çš„ç‰©ç†ä¸€è‡´æ€§è¯„ä¼°æä¾›äº†ç§‘å­¦ã€å‡†ç¡®ã€å®ç”¨çš„é‡åŒ–å·¥å…·ï¼Œå®Œå…¨ç¬¦åˆæ‚¨æä¾›çš„æ•°å­¦è§„èŒƒè¦æ±‚ã€‚


# PC-Score å¯è§†åŒ–æ›´æ–°æ€»ç»“

## ğŸ¯ æ›´æ–°å†…å®¹

æ ¹æ®æ‚¨çš„è¦æ±‚ï¼Œæˆ‘ä»¬ä¿æŒäº†åŸæœ‰çš„æ¢¯åº¦æ£€æµ‹ç»˜å›¾å¸ƒå±€ï¼Œåªä¿®æ”¹äº†å³ä¸‹è§’çš„æ€»ç»“é¢æ¿æ¥æ˜¾ç¤ºPC-Scoreç›¸å…³ä¿¡æ¯ã€‚

## ğŸ“Š ä¿®æ”¹è¯¦æƒ…

### ä¿æŒä¸å˜çš„éƒ¨åˆ†
- **å·¦ä¸Šè§’**: å»¶è¿Ÿ vs æµé‡å…³ç³»å›¾ (Delay vs Traffic Relationship)
- **å³ä¸Šè§’**: è‡ªå½±å“æ¢¯åº¦å›¾ (Self-influence Gradient)  
- **å·¦ä¸‹è§’**: äº¤å‰å½±å“æ¢¯åº¦å›¾ (Cross-influence Gradients)
- **æ•´ä½“å¸ƒå±€**: 2Ã—2 å­å›¾å¸ƒå±€ä¿æŒä¸å˜
- **å›¾è¡¨æ ·å¼**: åŸæœ‰çš„çº¿æ¡ã€æ ‡è®°ã€é¢œè‰²ç­‰æ ·å¼ä¿æŒä¸å˜

### æ›´æ–°çš„éƒ¨åˆ†

#### å³ä¸‹è§’æ€»ç»“é¢æ¿
**åŸæ¥æ˜¾ç¤º**:
```
Physical Intuition Validation Summary
Overall Score: 75.0%

Self-gradient > 0: âœ“ PASS
Cross-gradient > 0: âœ“ PASS
Delay Monotonic: âœ— FAIL
Congestion Sensitivity: âœ“ PASS

Detailed Statistics:
Self-gradient positive ratio: 100.0%
Self-gradient mean: 0.001234
J_01 positive ratio: 100.0%
J_21 positive ratio: 15.0%
```

**ç°åœ¨æ˜¾ç¤º**:
```
PC-Score Physical Consistency Summary
Overall PC-Score: 0.8245
Status: âœ“ PASS

Component Scores:
S_self:    1.000 Ã— 0.35 = 0.3500
S_mono:    0.950 Ã— 0.25 = 0.2375
S_cross:   0.850 Ã— 0.15 = 0.1275
S_indep:   0.780 Ã— 0.15 = 0.1170
S_congest: 0.900 Ã— 0.10 = 0.0900

Detailed Statistics:
Self-gradient positive ratio: 100.0%
Self-gradient mean: 0.001234
J_01 positive ratio: 100.0%
J_21 positive ratio: 15.0%
```

#### å›¾è¡¨æ ‡é¢˜
**åŸæ¥**: `KAN Model - Gradient Physical Intuition Validation (Varying Path 1)`
**ç°åœ¨**: `KAN Model - PC-Score Physical Consistency Validation (Path 1)`

## ğŸ”§ æŠ€æœ¯å®ç°

### ä¿®æ”¹çš„ä»£ç ä½ç½®
**æ–‡ä»¶**: `/home/ubantu/net2vec/routenet/gradient_sanity_check.py`
**æ–¹æ³•**: `_visualize_pc_score()`

### å…³é”®æ”¹åŠ¨
1. **æ€»ç»“æ ‡é¢˜**: ä» "Physical Intuition Validation Summary" æ”¹ä¸º "PC-Score Physical Consistency Summary"
2. **æ€»åˆ†æ˜¾ç¤º**: ä»ç™¾åˆ†æ¯”æ ¼å¼æ”¹ä¸ºå°æ•°æ ¼å¼ (0.8245 vs 82.45%)
3. **ç»„ä»¶å¾—åˆ†**: æ·»åŠ äº†è¯¦ç»†çš„PC-Scoreç»„ä»¶è®¡ç®—æ˜¾ç¤º
4. **æƒé‡æ˜¾ç¤º**: æ˜¾ç¤ºæ¯ä¸ªç»„ä»¶çš„æƒé‡å’Œè´¡çŒ®å€¼
5. **çŠ¶æ€æ ¼å¼**: ä¿æŒ "âœ“ PASS" / "âœ— FAIL" æ ¼å¼
6. **ç»Ÿè®¡ä¿¡æ¯**: ä¿ç•™åŸæœ‰çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯

## âœ… éªŒè¯ç»“æœ

### è¯­æ³•æ£€æŸ¥
- âœ… gradient_sanity_check.py è¯­æ³•æ­£ç¡®
- âœ… PC-Scoreæ€»ç»“é¢æ¿å·²æ›´æ–°  
- âœ… ç»„ä»¶å¾—åˆ†æ˜¾ç¤ºå·²æ·»åŠ 
- âœ… æ ‡é¢˜å·²æ›´æ–°ä¸ºPC-Scoreä¸»é¢˜

### å¯è§†åŒ–æµ‹è¯•
- âœ… ä¿æŒåŸæœ‰2Ã—2å›¾è¡¨å¸ƒå±€
- âœ… å·¦ä¸Šï¼šå»¶è¿Ÿvsæµé‡å…³ç³»å›¾
- âœ… å³ä¸Šï¼šè‡ªå½±å“æ¢¯åº¦å›¾
- âœ… å·¦ä¸‹ï¼šäº¤å‰å½±å“æ¢¯åº¦å›¾  
- âœ… å³ä¸‹ï¼šPC-Scoreæ€»ç»“é¢æ¿ï¼ˆå·²æ›´æ–°ï¼‰
- âœ… æ–°çš„PC-Scoreæ ¼å¼åŒ–è¾“å‡º
- âœ… è¯¦ç»†çš„ç»„ä»¶å¾—åˆ†æ˜¾ç¤º

### PC-Scoreè®¡ç®—éªŒè¯  
- âœ… æ˜¾ç¤ºçš„PC-Score: 0.9220
- âœ… æ‰‹å·¥è®¡ç®—ç»“æœ: 0.9220
- âœ… è®¡ç®—æ­£ç¡®æ€§éªŒè¯é€šè¿‡

## ğŸ“ ç”Ÿæˆæ–‡ä»¶

æµ‹è¯•ç”Ÿæˆçš„å¯è§†åŒ–å›¾ç‰‡: `/home/ubantu/net2vec/test_output/pc_score_visualization_test.png`

## ğŸ¨ è§†è§‰æ•ˆæœ

æ–°çš„å³ä¸‹è§’é¢æ¿æä¾›äº†æ›´ä¸°å¯Œçš„ä¿¡æ¯ï¼š
- **PC-Scoreæ€»åˆ†**: æ¸…æ™°æ˜¾ç¤ºç‰©ç†ä¸€è‡´æ€§è¯„åˆ†
- **ç»„ä»¶è¯¦æƒ…**: æ˜¾ç¤ºæ¯ä¸ªç»„ä»¶çš„å¾—åˆ†ã€æƒé‡å’Œè´¡çŒ®  
- **é€šè¿‡çŠ¶æ€**: æ˜ç¡®çš„PASS/FAILçŠ¶æ€æŒ‡ç¤º
- **è¯¦ç»†ç»Ÿè®¡**: ä¿ç•™åŸæœ‰çš„æ¢¯åº¦ç»Ÿè®¡ä¿¡æ¯
- **æ ¼å¼ç¾è§‚**: ä½¿ç”¨ç­‰å®½å­—ä½“å’Œå¯¹é½æ ¼å¼

è¿™ç§è®¾è®¡æ—¢ä¿æŒäº†åŸæœ‰å›¾è¡¨çš„å®Œæ•´æ€§ï¼Œåˆæä¾›äº†PC-Scoreç³»ç»Ÿçš„è¯¦ç»†ä¿¡æ¯ï¼Œæ»¡è¶³äº†æ‚¨çš„å…·ä½“è¦æ±‚ã€‚
