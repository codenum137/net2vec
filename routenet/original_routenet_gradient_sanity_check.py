# -*- coding: utf-8 -*-
"""
åŸç‰ˆRouteNet TF1.xæ¨¡å‹æ¢¯åº¦ç‰©ç†æ„ä¹‰éªŒè¯
åŸºäºTensorFlow 1.xçš„æ¢¯åº¦è®¡ç®—å’ŒéªŒè¯
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os
import sys
import argparse
from tqdm import tqdm

# å¯¼å…¥åŸç‰ˆRouteNetç›¸å…³æ¨¡å—
sys.path.append(os.path.dirname(__file__))
from routenet import delay_model_fn, tfrecord_input_fn

# ç¦ç”¨TF2è¡Œä¸ºï¼Œä½¿ç”¨TF1.x
tf.compat.v1.disable_v2_behavior()

class HParams:
    """åŸç‰ˆRouteNetçš„è¶…å‚æ•°"""
    def __init__(self):
        self.batch_size = 32
        self.link_state_dim = 4
        self.path_state_dim = 2
        self.T = 3
        self.readout_units = 8
        self.readout_layers = 2
        self.dropout_rate = 0.5
        self.l2 = 0.1
        self.l2_2 = 0.01
        self.learn_embedding = True

class OriginalRouteNetGradientChecker:
    """åŸç‰ˆRouteNetæ¢¯åº¦ç‰©ç†æ„ä¹‰éªŒè¯å™¨"""
    
    def __init__(self, model_dir, target='delay'):
        self.model_dir = model_dir
        self.target = target
        self.hparams = HParams()
        self.session = None
        self.graph = None
        self.setup_model()
    
    def create_controlled_network(self):
        """
        åˆ›å»ºä¸€ä¸ªå¯æ§çš„å¤æ‚ç½‘ç»œæ‹“æ‰‘ï¼ˆä¸gradient_sanity_check.pyä¸€è‡´ï¼‰
        
        ç½‘ç»œç»“æ„:
        Node 0 ----[Link 0]---- Node 1 ----[Link 1]---- Node 2 ----[Link 2]---- Node 3
                                      |
                                      +----[Link 3]---- Node 4
        
        è·¯å¾„é…ç½®:
        - è·¯å¾„ 0: 0->1->2 (ä½¿ç”¨é“¾è·¯ 0, 1)
        - è·¯å¾„ 1: 0->1->4 (ä½¿ç”¨é“¾è·¯ 0, 3) 
        - è·¯å¾„ 2: 1->2->3 (ä½¿ç”¨é“¾è·¯ 1, 2)
        """
        n_nodes = 5
        n_links = 4
        n_paths = 3
        
        # é“¾è·¯å®¹é‡è®¾ç½®ï¼šåŸºäºçœŸå®æ•°æ®é›†ç‰¹å¾ (å®¹é‡èŒƒå›´: 10-40, å…¸å‹å€¼: [10,10,10,40])
        # ä½¿ç”¨æ•°æ®é›†ä¸­çš„å…¸å‹å®¹é‡å€¼ï¼Œç¡®ä¿ä¸è®­ç»ƒæ•°æ®ä¸€è‡´
        capacities = np.array([10.0, 10.0, 40.0, 20.0], dtype=np.float32)  
        # é“¾è·¯0: 10.0 (è¢«è·¯å¾„0,1å…±äº«ï¼Œä½å®¹é‡ï¼Œå®¹æ˜“å½¢æˆç“¶é¢ˆ)
        # é“¾è·¯1: 10.0 (è¢«è·¯å¾„0,2å…±äº«ï¼Œä½å®¹é‡ï¼Œå®¹æ˜“å½¢æˆç“¶é¢ˆ) 
        # é“¾è·¯2: 40.0 (ä»…è·¯å¾„2ä½¿ç”¨ï¼Œé«˜å®¹é‡)
        # é“¾è·¯3: 20.0 (ä»…è·¯å¾„1ä½¿ç”¨ï¼Œä¸­ç­‰å®¹é‡)
        
        # è·¯å¾„-é“¾è·¯æ˜ å°„ï¼Œæ³¨æ„æ•°æ®ç±»å‹
        # è·¯å¾„0: é“¾è·¯0, é“¾è·¯1  
        # è·¯å¾„1: é“¾è·¯0, é“¾è·¯3
        # è·¯å¾„2: é“¾è·¯1, é“¾è·¯2
        links = np.array([0, 1, 0, 3, 1, 2], dtype=np.int32)  # å±•å¹³çš„é“¾è·¯ç´¢å¼•
        paths = np.array([0, 0, 1, 1, 2, 2], dtype=np.int32)  # å¯¹åº”çš„è·¯å¾„ç´¢å¼•  
        sequences = np.array([0, 1, 0, 1, 0, 1], dtype=np.int32)  # è·¯å¾„å†…åºåˆ—
        
        # åŸºç¡€æµé‡é…ç½®ï¼šåŸºäºçœŸå®æ•°æ®é›†ç‰¹å¾ (æµé‡èŒƒå›´: 0.086-1.103, å…¸å‹å€¼: [0.33,0.55,0.78,0.91])
        base_traffic = np.array([0.33, 0.55, 0.78], dtype=np.float32)  # ä½¿ç”¨æ•°æ®é›†25%-75%åˆ†ä½æ•°
        
        # æ•°æ®åŒ…æ•°é‡
        packets = np.array([1000.0, 800.0, 1200.0], dtype=np.float32)
        
        network_config = {
            'capacities': capacities,
            'links': links,
            'paths': paths,
            'sequences': sequences,
            'n_links': n_links,
            'n_paths': n_paths,
            'packets': packets,
            'base_traffic': base_traffic,
            'bottleneck_links': [0, 1],  # ç“¶é¢ˆé“¾è·¯
            'shared_paths': [(0, 2), (0, 1)]  # å…±äº«é“¾è·¯çš„è·¯å¾„å¯¹
        }
        
        return network_config
    
    def setup_model(self):
        """è®¾ç½®TF1.xæ¨¡å‹å›¾"""
        print("Setting up original RouteNet model from: {}".format(self.model_dir))
        
        self.graph = tf.Graph()
        with self.graph.as_default():
            # åˆ›å»ºå ä½ç¬¦ç”¨äºè¾“å…¥ç‰¹å¾ - ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´æ€§
            self.traffic_ph = tf.compat.v1.placeholder(tf.float32, shape=[None], name='traffic_input')
            self.capacities_ph = tf.compat.v1.placeholder(tf.float32, shape=[None], name='capacities_input')
            self.links_ph = tf.compat.v1.placeholder(tf.int32, shape=[None], name='links_input')
            self.paths_ph = tf.compat.v1.placeholder(tf.int32, shape=[None], name='paths_input')
            self.sequences_ph = tf.compat.v1.placeholder(tf.int32, shape=[None], name='sequences_input')
            self.packets_ph = tf.compat.v1.placeholder(tf.float32, shape=[None], name='packets_input')
            self.n_links_ph = tf.compat.v1.placeholder(tf.int32, shape=[], name='n_links_input')
            self.n_paths_ph = tf.compat.v1.placeholder(tf.int32, shape=[], name='n_paths_input')
            
            # æ„é€ ç‰¹å¾å­—å…¸
            features = {
                'traffic': self.traffic_ph,
                'capacities': self.capacities_ph,
                'links': self.links_ph,
                'paths': self.paths_ph,
                'sequences': self.sequences_ph,
                'packets': self.packets_ph,
                'n_links': self.n_links_ph,
                'n_paths': self.n_paths_ph
            }
            
            # æ„é€ è™šæ‹Ÿæ ‡ç­¾ï¼ˆé¢„æµ‹æ—¶ä¸ä¼šä½¿ç”¨ï¼‰
            labels = {
                'delay': tf.zeros_like(self.traffic_ph),
                'jitter': tf.zeros_like(self.traffic_ph),
                'packets': self.packets_ph,
                'drops': tf.zeros_like(self.traffic_ph)
            }
            
            # åˆ›å»ºæ¨¡å‹
            if self.target == 'delay':
                model_spec = delay_model_fn(features, labels, tf.estimator.ModeKeys.PREDICT, self.hparams)
            else:
                raise NotImplementedError("Only delay model is supported for now")
            
            self.predictions = model_spec.predictions
            
            # è·å–å»¶è¿Ÿé¢„æµ‹ï¼ˆä½ç½®å‚æ•°ï¼‰
            if 'delay' in self.predictions:
                self.delay_output = self.predictions['delay']
            else:
                raise ValueError("Delay prediction not found in model outputs")
            
            # è®¡ç®—é›…å¯æ¯”çŸ©é˜µï¼šâˆ‚delay/âˆ‚traffic
            self.jacobian = tf.gradients(self.delay_output, self.traffic_ph)[0]
            
            # åˆ›å»ºsaver
            self.saver = tf.compat.v1.train.Saver()
        
        # åˆ›å»ºsessionå¹¶åŠ è½½æƒé‡
        self.session = tf.compat.v1.Session(graph=self.graph)
        checkpoint_path = tf.train.latest_checkpoint(self.model_dir)
        if checkpoint_path is None:
            raise ValueError(f"No checkpoint found in {self.model_dir}")
        
        self.saver.restore(self.session, checkpoint_path)
        print(f"Model restored from {checkpoint_path}")
    
    def _apply_routenet_scaling(self, features):
        """
        åº”ç”¨ä¸routenet_tf2.pyä¸­ç›¸åŒçš„æ•°æ®æ ‡å‡†åŒ–
        
        RouteNetæ ‡å‡†åŒ–å…¬å¼:
        - æµé‡: (val - 0.18) / 0.15
        - å®¹é‡: val / 10.0
        """
        scaled_features = features.copy()
        
        # æ ‡å‡†åŒ–æµé‡
        if 'traffic' in features:
            scaled_features['traffic'] = (features['traffic'] - 0.18) / 0.15
        
        # æ ‡å‡†åŒ–å®¹é‡
        if 'capacities' in features:
            scaled_features['capacities'] = features['capacities'] / 10.0
            
        return scaled_features
    
    def compute_jacobian(self, sample_features):
        """è®¡ç®—ç»™å®šæ ·æœ¬çš„é›…å¯æ¯”çŸ©é˜µ"""
        feed_dict = {
            self.traffic_ph: sample_features['traffic'],
            self.capacities_ph: sample_features['capacities'],
            self.links_ph: sample_features['links'],
            self.paths_ph: sample_features['paths'],
            self.sequences_ph: sample_features['sequences'],
            self.packets_ph: sample_features['packets'],
            self.n_links_ph: sample_features['n_links'],
            self.n_paths_ph: sample_features['n_paths']
        }
        
        # è¿è¡Œè®¡ç®—
        jacobian_val, delay_pred = self.session.run([self.jacobian, self.delay_output], feed_dict)
        
        return jacobian_val, delay_pred
    
    def traffic_sweep_experiment(self, network_config, path_to_vary=0, 
                               traffic_range=(0.1, 1.0), num_points=20):
        """
        æµé‡æ‰«æå®éªŒï¼šå›ºå®šå…¶ä»–è·¯å¾„æµé‡ï¼Œå˜åŒ–æŒ‡å®šè·¯å¾„æµé‡
        
        Args:
            network_config: ç½‘ç»œé…ç½®
            path_to_vary: è¦å˜åŒ–æµé‡çš„è·¯å¾„ç´¢å¼•
            traffic_range: æµé‡å˜åŒ–èŒƒå›´ (min, max) - åŸºäºæ•°æ®é›†å®é™…èŒƒå›´0.086-1.103
            num_points: é‡‡æ ·ç‚¹æ•°é‡
        
        Returns:
            experiment_results: å®éªŒç»“æœå­—å…¸
        """
        print(f"æ‰§è¡ŒåŸç‰ˆRouteNetæµé‡æ‰«æå®éªŒï¼šå˜åŒ–è·¯å¾„ {path_to_vary} çš„æµé‡...")
        
        # ç”Ÿæˆæµé‡åºåˆ—
        traffic_values = np.linspace(traffic_range[0], traffic_range[1], num_points)
        
        results = {
            'traffic_values': traffic_values,
            'delay_predictions': [],
            'jacobian_matrices': [],
            'diagonal_gradients': [],  # J_ii: âˆ‚D_i/âˆ‚T_i
            'cross_gradients': {},     # J_ij: âˆ‚D_i/âˆ‚T_j (iâ‰ j)
        }
        
        # ä¸ºæ¯ä¸ªè·¯å¾„å¯¹è®°å½•äº¤å‰æ¢¯åº¦
        for i in range(network_config['n_paths']):
            if i != path_to_vary:
                results['cross_gradients'][f'J_{i}{path_to_vary}'] = []
        
        base_traffic = network_config['base_traffic'].copy()
        
        for traffic_val in tqdm(traffic_values, desc="æµé‡æ‰«æ"):
            # è®¾ç½®å½“å‰æµé‡
            current_traffic = base_traffic.copy()
            current_traffic[path_to_vary] = traffic_val
            
            # æ„é€ åŸå§‹æ ·æœ¬ç‰¹å¾
            raw_features = {
                'traffic': current_traffic,
                'capacities': network_config['capacities'],
                'links': network_config['links'],
                'paths': network_config['paths'],
                'sequences': network_config['sequences'],
                'n_links': network_config['n_links'],
                'n_paths': network_config['n_paths'],
                'packets': network_config['packets']
            }
            
            # âš ï¸ é‡è¦ï¼šåº”ç”¨ä¸routenet_tf2.pyç›¸åŒçš„æ•°æ®æ ‡å‡†åŒ–
            sample_features = self._apply_routenet_scaling(raw_features)
            
            # è®¡ç®—é›…å¯æ¯”çŸ©é˜µå’Œå»¶è¿Ÿé¢„æµ‹
            try:
                jacobian_val, delay_pred = self.compute_jacobian(sample_features)
                
                if jacobian_val is not None:
                    # é‡å¡‘é›…å¯æ¯”çŸ©é˜µä¸º [n_paths, n_paths] å½¢çŠ¶
                    n_paths = network_config['n_paths']
                    if jacobian_val.ndim == 1:
                        # å¦‚æœæ˜¯ä¸€ç»´ï¼Œè¯´æ˜æ¯ä¸ªè¾“å‡ºå¯¹åº”ä¸€ä¸ªæ¢¯åº¦
                        jacobian_matrix = np.diag(jacobian_val)
                    else:
                        jacobian_matrix = jacobian_val.reshape(n_paths, n_paths)
                    
                    results['delay_predictions'].append(delay_pred)
                    results['jacobian_matrices'].append(jacobian_matrix)
                    results['diagonal_gradients'].append(np.diag(jacobian_matrix))
                    
                    # è®°å½•äº¤å‰æ¢¯åº¦
                    for i in range(n_paths):
                        if i != path_to_vary:
                            results['cross_gradients'][f'J_{i}{path_to_vary}'].append(
                                jacobian_matrix[i, path_to_vary]
                            )
                else:
                    print(f"Warning: No gradient computed for traffic {traffic_val}")
                    
            except Exception as e:
                print(f"Error computing gradient for traffic {traffic_val}: {e}")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        results['delay_predictions'] = np.array(results['delay_predictions'])
        results['jacobian_matrices'] = np.array(results['jacobian_matrices'])
        results['diagonal_gradients'] = np.array(results['diagonal_gradients'])
        
        for key in results['cross_gradients']:
            results['cross_gradients'][key] = np.array(results['cross_gradients'][key])
        
        return results
    
    def _analyze_path_topology(self, network_config):
        """
        åˆ†æç½‘ç»œæ‹“æ‰‘ï¼Œæ‰¾å‡ºè·¯å¾„é—´çš„é“¾è·¯å…±äº«å…³ç³»
        
        Returns:
            shared_links_matrix: [n_paths, n_paths] å¸ƒå°”çŸ©é˜µï¼Œ
                                shared_links_matrix[i][j] = True è¡¨ç¤ºè·¯å¾„iå’Œè·¯å¾„jå…±äº«è‡³å°‘ä¸€æ¡é“¾è·¯
        """
        n_paths = network_config['n_paths']
        links = network_config['links']
        paths = network_config['paths']
        
        # æ„å»ºæ¯æ¡è·¯å¾„ä½¿ç”¨çš„é“¾è·¯é›†åˆ
        path_links = [set() for _ in range(n_paths)]
        
        for link_idx, path_idx in zip(links, paths):
            path_links[path_idx].add(link_idx)
        
        # æ„å»ºè·¯å¾„é—´å…±äº«é“¾è·¯çŸ©é˜µ
        shared_links_matrix = np.zeros((n_paths, n_paths), dtype=bool)
        shared_links_count = np.zeros((n_paths, n_paths), dtype=int)
        
        for i in range(n_paths):
            for j in range(n_paths):
                if i != j:
                    shared_links = path_links[i].intersection(path_links[j])
                    shared_links_matrix[i][j] = len(shared_links) > 0
                    shared_links_count[i][j] = len(shared_links)
        
        return shared_links_matrix, shared_links_count, path_links

    def _compute_s_self_formula(self, diagonal_gradients, path_to_vary, n_samples):
        """
        è®¡ç®— S_self = (1/N) * Î£ I(g_kk^(i) >= 0)
        è‡ªå½±å“æ¢¯åº¦ä¸ºæ­£çš„æ¯”ä¾‹
        """
        self_gradients = diagonal_gradients[:, path_to_vary]
        positive_count = np.sum(self_gradients >= 0)
        return positive_count / n_samples

    def _compute_s_mono_formula(self, delay_predictions, path_to_vary, n_samples):
        """
        è®¡ç®— S_mono = (1/N) * Î£ I(d_k^(i+1) >= d_k^(i))
        å»¶è¿Ÿå•è°ƒæ€§ï¼šåç»­æµé‡ä¸‹çš„å»¶è¿Ÿ >= å‰ä¸€ä¸ªæµé‡ä¸‹çš„å»¶è¿Ÿ
        """
        delays = delay_predictions[:, path_to_vary]
        if len(delays) < 2:
            return 1.0
        
        # è®¡ç®—ç›¸é‚»å»¶è¿Ÿå·®
        delay_diffs = np.diff(delays)
        # å•è°ƒé€’å¢ï¼ˆå…è®¸å°çš„æ•°å€¼è¯¯å·®ï¼‰
        monotonic_count = np.sum(delay_diffs >= -1e-8)
        return monotonic_count / (n_samples - 1)

    def _compute_s_cross_formula(self, cross_gradients, shared_links_matrix, 
                                path_to_vary, n_paths, n_samples):
        """
        è®¡ç®— S_cross = (1/M) * Î£_m (1/N) * Î£_i I(g_km^(i) >= 0)
        å…±äº«é“¾è·¯è·¯å¾„çš„äº¤å‰å½±å“æ¢¯åº¦ä¸ºæ­£çš„æ¯”ä¾‹
        M: ä¸path_to_varyå…±äº«é“¾è·¯çš„è·¯å¾„æ•°é‡
        """
        shared_path_scores = []
        
        for key, cross_grad in cross_gradients.items():
            # è§£ææ¢¯åº¦é”®ï¼šJ_ij è¡¨ç¤º âˆ‚D_i/âˆ‚T_j
            parts = key.split('_')
            if len(parts) == 2:
                i = int(parts[1][0])  # å—å½±å“çš„è·¯å¾„
                j = int(parts[1][1])  # å½±å“è·¯å¾„ï¼ˆåº”è¯¥æ˜¯path_to_varyï¼‰
                
                # æ£€æŸ¥æ˜¯å¦å…±äº«é“¾è·¯
                if j == path_to_vary and shared_links_matrix[i][j]:
                    positive_count = np.sum(cross_grad >= 0)
                    path_score = positive_count / n_samples
                    shared_path_scores.append(path_score)
        
        if len(shared_path_scores) == 0:
            return 1.0  # æ— å…±äº«è·¯å¾„æ—¶ç»™æ»¡åˆ†
        
        return np.mean(shared_path_scores)

    def _compute_s_indep_formula(self, cross_gradients, shared_links_matrix, 
                                path_to_vary, n_paths, n_samples):
        """
        è®¡ç®— S_indep = (1/L) * Î£_l (1/N) * Î£_i I(|g_kl^(i)| <= Îµ)
        ç‹¬ç«‹è·¯å¾„çš„äº¤å‰å½±å“æ¢¯åº¦æ¥è¿‘é›¶çš„æ¯”ä¾‹
        L: ä¸path_to_varyä¸å…±äº«é“¾è·¯çš„è·¯å¾„æ•°é‡
        Îµ: å¾ˆå°çš„é˜ˆå€¼ï¼Œä¾‹å¦‚0.001
        """
        epsilon = 0.001
        independent_path_scores = []
        
        for key, cross_grad in cross_gradients.items():
            # è§£ææ¢¯åº¦é”®ï¼šJ_ij è¡¨ç¤º âˆ‚D_i/âˆ‚T_j
            parts = key.split('_')
            if len(parts) == 2:
                i = int(parts[1][0])  # å—å½±å“çš„è·¯å¾„
                j = int(parts[1][1])  # å½±å“è·¯å¾„ï¼ˆåº”è¯¥æ˜¯path_to_varyï¼‰
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºç‹¬ç«‹è·¯å¾„ï¼ˆä¸å…±äº«é“¾è·¯ï¼‰
                if j == path_to_vary and not shared_links_matrix[i][j]:
                    small_gradient_count = np.sum(np.abs(cross_grad) <= epsilon)
                    path_score = small_gradient_count / n_samples
                    independent_path_scores.append(path_score)
        
        if len(independent_path_scores) == 0:
            return 1.0  # æ— ç‹¬ç«‹è·¯å¾„æ—¶ç»™æ»¡åˆ†
        
        return np.mean(independent_path_scores)

    def _compute_s_congest_formula(self, diagonal_gradients, path_to_vary, n_samples):
        """
        è®¡ç®— S_congest = I(g_mean_high >= Î± * g_mean_low)
        æ‹¥å¡æ•æ„Ÿæ€§ï¼šé«˜æµé‡åŒºåŸŸçš„å¹³å‡æ¢¯åº¦ >= Î±å€ä½æµé‡åŒºåŸŸçš„å¹³å‡æ¢¯åº¦
        Î±: æ‹¥å¡æ•æ„Ÿå› å­ï¼Œä¾‹å¦‚1.2
        """
        alpha = 1.2
        self_gradients = diagonal_gradients[:, path_to_vary]
        
        if n_samples < 4:
            return 1.0
        
        # è®¡ç®—ä½æµé‡åŒºåŸŸï¼ˆå‰25%ï¼‰å’Œé«˜æµé‡åŒºåŸŸï¼ˆå25%ï¼‰çš„å¹³å‡æ¢¯åº¦
        low_traffic_end = max(1, n_samples // 4)
        high_traffic_start = max(low_traffic_end, n_samples - n_samples // 4)
        
        g_mean_low = np.mean(self_gradients[:low_traffic_end])
        g_mean_high = np.mean(self_gradients[high_traffic_start:])
        
        # é¿å…é™¤é›¶é”™è¯¯
        if g_mean_low <= 1e-10:
            return 1.0 if g_mean_high > 1e-10 else 0.0
        
        return 1.0 if g_mean_high >= alpha * g_mean_low else 0.0

    def _print_pc_score_results(self, validation_results, path_to_vary):
        """æ‰“å°PC-Scoreç»“æœ"""
        print("\n" + "="*70)
        print("PC-Score (ç‰©ç†ä¸€è‡´æ€§è¯„åˆ†) ç»“æœ - åŸç‰ˆRouteNet")
        print("="*70)
        
        pc_score = validation_results['pc_score']
        components = validation_results['components']
        weights = validation_results['weights']
        
        print(f"\nğŸ¯ PC-Score æ€»åˆ†: {pc_score:.4f}")
        print(f"   éªŒè¯çŠ¶æ€: {'âœ… é€šè¿‡' if validation_results['validation_passed'] else 'âŒ æœªé€šè¿‡'}")
        print(f"   è·¯å¾„ {path_to_vary} çš„ç‰©ç†ä¸€è‡´æ€§è¯„ä¼°")
        
        print(f"\nğŸ“Š å„ç»„ä»¶å¾—åˆ†:")
        print(f"   S_self   (è‡ªå½±å“ä¸ºæ­£):     {components['s_self']:.4f} Ã— {weights['self']:.2f} = {components['s_self'] * weights['self']:.4f}")
        print(f"   S_mono   (å»¶è¿Ÿå•è°ƒæ€§):     {components['s_mono']:.4f} Ã— {weights['mono']:.2f} = {components['s_mono'] * weights['mono']:.4f}")
        print(f"   S_cross  (å…±äº«è·¯å¾„å½±å“):   {components['s_cross']:.4f} Ã— {weights['cross']:.2f} = {components['s_cross'] * weights['cross']:.4f}")
        print(f"   S_indep  (ç‹¬ç«‹è·¯å¾„é›¶å½±å“): {components['s_indep']:.4f} Ã— {weights['indep']:.2f} = {components['s_indep'] * weights['indep']:.4f}")
        print(f"   S_congest(æ‹¥å¡æ•æ„Ÿæ€§):     {components['s_congest']:.4f} Ã— {weights['congest']:.2f} = {components['s_congest'] * weights['congest']:.4f}")
        
        print(f"\nğŸ“ˆ è§£é‡Š:")
        # PC-ScoreåŒºé—´è§£é‡Š
        if pc_score >= 0.95:
            print(f"   ğŸŒŸ ä¼˜ç§€ - æ¨¡å‹å®Œå…¨æŒæ¡äº†ç½‘ç»œç‰©ç†è§„å¾‹")
        elif pc_score >= 0.85:
            print(f"   â­ è‰¯å¥½ - æ¨¡å‹å¾ˆå¥½åœ°æŒæ¡äº†ç½‘ç»œç‰©ç†è§„å¾‹")
        elif pc_score >= 0.7:
            print(f"   âœ“ å¯æ¥å— - æ¨¡å‹åŸºæœ¬æŒæ¡äº†ç½‘ç»œç‰©ç†è§„å¾‹")
        elif pc_score >= 0.5:
            print(f"   âš  ä¸€èˆ¬ - æ¨¡å‹éƒ¨åˆ†æŒæ¡äº†ç½‘ç»œç‰©ç†è§„å¾‹")
        else:
            print(f"   âŒ è¾ƒå·® - æ¨¡å‹æœªèƒ½å¾ˆå¥½åœ°å­¦ä¹ ç½‘ç»œç‰©ç†è§„å¾‹")

    def validate_physical_intuition(self, experiment_results, network_config, 
                                   path_to_vary, output_dir):
        """
        éªŒè¯æ¢¯åº¦çš„ç‰©ç†æ„ä¹‰ (æ‹“æ‰‘æ„ŸçŸ¥ç‰ˆæœ¬)
        
        ç‰©ç†ç›´è§‰éªŒè¯æ ‡å‡†:
        1. è‡ªå½±å“æ¢¯åº¦ J_ii > 0ï¼šè·¯å¾„è‡ªå·±çš„æµé‡å¢åŠ åº”è¯¥å¢åŠ è‡ªå·±çš„å»¶è¿Ÿ
        2. äº¤å‰å½±å“æ¢¯åº¦ J_ij > 0ï¼šä»…å¯¹å…±äº«é“¾è·¯çš„è·¯å¾„éªŒè¯äº¤å‰å½±å“
        3. æ¥è¿‘æ‹¥å¡æ—¶æ¢¯åº¦å¢å¤§ï¼šå½“æµé‡æ¥è¿‘é“¾è·¯å®¹é‡æ—¶ï¼Œæ¢¯åº¦åº”è¯¥æ˜¾è‘—å¢å¤§
        4. å»¶è¿Ÿå•è°ƒé€’å¢ï¼šéšç€æµé‡å¢åŠ ï¼Œå»¶è¿Ÿåº”è¯¥å•è°ƒé€’å¢
        """
        os.makedirs(output_dir, exist_ok=True)
        
        # åˆ†æç½‘ç»œæ‹“æ‰‘
        shared_links_matrix, shared_links_count, path_links = self._analyze_path_topology(network_config)
        
        traffic_values = experiment_results['traffic_values']
        delay_predictions = experiment_results['delay_predictions']
        diagonal_gradients = experiment_results['diagonal_gradients']
        cross_gradients = experiment_results['cross_gradients']
        
        n_paths = network_config['n_paths']
        n_samples = len(traffic_values)
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        if len(diagonal_gradients) == 0:
            print("é”™è¯¯ï¼šæ²¡æœ‰æˆåŠŸè®¡ç®—ä»»ä½•æ¢¯åº¦å€¼")
            return {'pc_score': 0.0, 'validation_passed': False, 'components': {}, 'weights': {}}

        # PC-Scoreæƒé‡é…ç½®ï¼ˆé‡ç‚¹å¼ºè°ƒç‰©ç†è§„å¾‹é‡è¦æ€§å±‚æ¬¡ï¼‰
        weights = {
            'self': 0.35,    # è‡ªå½±å“ä¸ºæ­£ - æœ€é‡è¦çš„åŸºç¡€ç‰©ç†è§„å¾‹
            'mono': 0.25,    # å»¶è¿Ÿå•è°ƒæ€§ - æ ¸å¿ƒç‰©ç†ç‰¹æ€§ 
            'cross': 0.15,   # å…±äº«è·¯å¾„å½±å“ - æ‹“æ‰‘æ„ŸçŸ¥
            'indep': 0.15,   # ç‹¬ç«‹è·¯å¾„é›¶å½±å“ - æ‹“æ‰‘æ„ŸçŸ¥
            'congest': 0.10  # æ‹¥å¡æ•æ„Ÿæ€§ - é«˜çº§ç‰¹æ€§
        }

        # 1. è®¡ç®—PC-Scoreå„ç»„ä»¶
        s_self = self._compute_s_self_formula(diagonal_gradients, path_to_vary, n_samples)
        s_mono = self._compute_s_mono_formula(delay_predictions, path_to_vary, n_samples) 
        s_cross = self._compute_s_cross_formula(cross_gradients, shared_links_matrix, 
                                              path_to_vary, n_paths, n_samples)
        s_indep = self._compute_s_indep_formula(cross_gradients, shared_links_matrix, 
                                              path_to_vary, n_paths, n_samples)
        s_congest = self._compute_s_congest_formula(diagonal_gradients, path_to_vary, n_samples)
        
        # 2. è®¡ç®—åŠ æƒPC-Score
        pc_score = (weights['self'] * s_self + 
                   weights['mono'] * s_mono + 
                   weights['cross'] * s_cross + 
                   weights['indep'] * s_indep + 
                   weights['congest'] * s_congest)
        
        # 3. æ„å»ºéªŒè¯ç»“æœ
        validation_results = {
            'pc_score': pc_score,
            'validation_passed': pc_score >= 0.7,
            'components': {
                's_self': s_self,
                's_mono': s_mono, 
                's_cross': s_cross,
                's_indep': s_indep,
                's_congest': s_congest
            },
            'weights': weights,
            'topology_info': {
                'shared_links_matrix': shared_links_matrix,
                'shared_links_count': shared_links_count,
                'path_links': path_links
            }
        }
        
        # æ‰“å°PC-Scoreç»“æœ
        self._print_pc_score_results(validation_results, path_to_vary)
        
        # å¯è§†åŒ–ç»“æœ
        self._visualize_results(experiment_results, path_to_vary, output_dir, validation_results)
        
        return validation_results
    
    def _visualize_results(self, experiment_results, path_to_vary, output_dir, validation_results):
        """å¯è§†åŒ–éªŒè¯ç»“æœ"""
        plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        traffic_values = experiment_results['traffic_values']
        delay_predictions = experiment_results['delay_predictions']
        diagonal_gradients = experiment_results['diagonal_gradients']
        cross_gradients = experiment_results['cross_gradients']
        
        if len(delay_predictions) == 0 or len(diagonal_gradients) == 0:
            print("Warning: No data to visualize")
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. å»¶è¿Ÿ vs æµé‡
        ax1 = axes[0, 0]
        n_paths = delay_predictions.shape[1]
        for i in range(n_paths):
            ax1.plot(traffic_values, delay_predictions[:, i], 
                    label=f'Path {i}', marker='o', markersize=3)
        ax1.set_xlabel(f'Path {path_to_vary} Traffic')
        ax1.set_ylabel('Predicted Delay')
        ax1.set_title('Delay vs Traffic (Original RouteNet)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. è‡ªå½±å“æ¢¯åº¦
        ax2 = axes[0, 1]
        if diagonal_gradients.shape[1] > path_to_vary:
            self_gradients = diagonal_gradients[:, path_to_vary]
            ax2.plot(traffic_values, self_gradients, 'r-', marker='s', markersize=4)
            ax2.set_xlabel(f'Path {path_to_vary} Traffic')
            ax2.set_ylabel(f'âˆ‚D_{path_to_vary}/âˆ‚T_{path_to_vary}')
            ax2.set_title(f'Self-influence Gradient (Original RouteNet)')
            ax2.grid(True, alpha=0.3)
            ax2.axhline(y=0, color='k', linestyle='--', alpha=0.5)
        
        # 3. äº¤å‰å½±å“æ¢¯åº¦
        ax3 = axes[1, 0]
        colors = ['blue', 'green', 'orange', 'purple']
        for i, (key, cross_grad) in enumerate(cross_gradients.items()):
            if len(cross_grad) > 0:
                ax3.plot(traffic_values, cross_grad, color=colors[i % len(colors)],
                        label=key, marker='^', markersize=3)
        ax3.set_xlabel(f'Path {path_to_vary} Traffic')
        ax3.set_ylabel('Cross-influence Gradient')
        ax3.set_title('Cross-influence Gradients (Original RouteNet)')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        ax3.axhline(y=0, color='k', linestyle='--', alpha=0.5)
        
        # 4. PC-Scoreç»“æœæ–‡æœ¬æ€»ç»“
        ax4 = axes[1, 1]
        ax4.axis('off')  # éšè—åæ ‡è½´
        
        # åˆ›å»ºPC-ScoreéªŒè¯ç»“æœæ–‡æœ¬æ€»ç»“
        pc_score = validation_results['pc_score']
        components = validation_results['components']
        weights = validation_results['weights']
        
        summary_text = f"PC-Score Physical Consistency Summary\n"
        summary_text += f"Overall PC-Score: {pc_score:.4f}\n"
        summary_text += f"Status: {'âœ“ PASS' if validation_results['validation_passed'] else 'âœ— FAIL'}\n\n"
        
        # PC-Scoreç»„ä»¶å¾—åˆ†
        summary_text += f"Component Scores:\n"
        summary_text += f"S_self:    {components['s_self']:.3f} Ã— {weights['self']:.2f} = {components['s_self'] * weights['self']:.4f}\n"
        summary_text += f"S_mono:    {components['s_mono']:.3f} Ã— {weights['mono']:.2f} = {components['s_mono'] * weights['mono']:.4f}\n"
        summary_text += f"S_cross:   {components['s_cross']:.3f} Ã— {weights['cross']:.2f} = {components['s_cross'] * weights['cross']:.4f}\n"
        summary_text += f"S_indep:   {components['s_indep']:.3f} Ã— {weights['indep']:.2f} = {components['s_indep'] * weights['indep']:.4f}\n"
        summary_text += f"S_congest: {components['s_congest']:.3f} Ã— {weights['congest']:.2f} = {components['s_congest'] * weights['congest']:.4f}\n"
        
        # æ·»åŠ è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        if diagonal_gradients.shape[1] > path_to_vary:
            self_gradients = diagonal_gradients[:, path_to_vary]
            self_pos_ratio = np.sum(self_gradients > 0) / len(self_gradients)
            summary_text += f"\nDetailed Statistics:\n"
            summary_text += f"Self-gradient positive ratio: {self_pos_ratio:.1%}\n"
            summary_text += f"Self-gradient mean: {np.mean(self_gradients):.6f}\n"
        
            for key, cross_grad in cross_gradients.items():
                if len(cross_grad) > 0:
                    cross_pos_ratio = np.sum(cross_grad > 0) / len(cross_grad)
                    summary_text += f"{key} positive ratio: {cross_pos_ratio:.1%}\n"
        
        ax4.text(0.05, 0.95, summary_text, transform=ax4.transAxes, fontsize=10,
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        
        plt.suptitle(f'Original RouteNet - PC-Score Physical Consistency Validation (Path {path_to_vary})', 
                     fontsize=16, y=0.95)
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, f'original_routenet_sanity_check_path_{path_to_vary}.png'), 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        # ä¿å­˜ç®€åŒ–çš„PC-Scoreç»“æœ
        with open(os.path.join(output_dir, f'original_routenet_pc_score_results_path_{path_to_vary}.txt'), 'w', encoding='utf-8') as f:
            f.write(f"Original RouteNet - PC-Score Physical Consistency Results\n")
            f.write("="*60 + "\n")
            f.write(f"Path: {path_to_vary}\n")
            f.write(f"PC-Score: {validation_results['pc_score']:.4f}\n")
            f.write(f"Status: {'PASS' if validation_results['validation_passed'] else 'FAIL'}\n\n")
            
            # PC-Scoreç»„ä»¶è¯¦æƒ…
            components = validation_results['components']
            weights = validation_results['weights']
            f.write("PC-Score Components:\n")
            f.write("-" * 30 + "\n")
            f.write(f"S_self:    {components['s_self']:.4f} Ã— {weights['self']:.2f} = {components['s_self'] * weights['self']:.4f}\n")
            f.write(f"S_mono:    {components['s_mono']:.4f} Ã— {weights['mono']:.2f} = {components['s_mono'] * weights['mono']:.4f}\n")
            f.write(f"S_cross:   {components['s_cross']:.4f} Ã— {weights['cross']:.2f} = {components['s_cross'] * weights['cross']:.4f}\n")
            f.write(f"S_indep:   {components['s_indep']:.4f} Ã— {weights['indep']:.2f} = {components['s_indep'] * weights['indep']:.4f}\n")
            f.write(f"S_congest: {components['s_congest']:.4f} Ã— {weights['congest']:.2f} = {components['s_congest'] * weights['congest']:.4f}\n")
    
    def close(self):
        """å…³é—­TensorFlow session"""
        if self.session:
            self.session.close()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='åŸç‰ˆRouteNetæ¢¯åº¦ç‰©ç†æ„ä¹‰éªŒè¯')
    parser.add_argument('--model_dir', default='models/routenet/delay', help='åŸç‰ˆRouteNetæ¨¡å‹ç›®å½•')
    parser.add_argument('--output_dir', default='original_routenet_gradient_check', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--traffic_min', type=float, default=0.1, 
                       help='æœ€å°æµé‡å€¼ (åŸºäºæ•°æ®é›†èŒƒå›´0.086-1.103)')
    parser.add_argument('--traffic_max', type=float, default=1.0, 
                       help='æœ€å¤§æµé‡å€¼ (åŸºäºæ•°æ®é›†èŒƒå›´0.086-1.103)')
    parser.add_argument('--num_points', type=int, default=10, 
                       help='æµé‡é‡‡æ ·ç‚¹æ•°é‡')
    
    args = parser.parse_args()
    
    try:
        print("åˆå§‹åŒ–åŸç‰ˆRouteNetæ¢¯åº¦éªŒè¯å™¨...")
        checker = OriginalRouteNetGradientChecker(args.model_dir, target='delay')
        
        print("åˆ›å»ºå¯æ§ç½‘ç»œæ‹“æ‰‘...")
        network_config = checker.create_controlled_network()
        
        print("ç½‘ç»œé…ç½®:")
        print(f"  èŠ‚ç‚¹æ•°: 5, é“¾è·¯æ•°: {network_config['n_links']}, è·¯å¾„æ•°: {network_config['n_paths']}")
        print(f"  é“¾è·¯å®¹é‡: {network_config['capacities']}")
        print(f"  åŸºç¡€æµé‡: {network_config['base_traffic']}")
        print(f"  ç“¶é¢ˆé“¾è·¯: {network_config['bottleneck_links']}")
        
        # å¯¹æ¯æ¡è·¯å¾„è¿›è¡Œæµé‡æ‰«æå®éªŒ
        overall_results = {}
        
        for path_id in range(network_config['n_paths']):
            print(f"\n{'='*60}")
            print(f"æµ‹è¯•è·¯å¾„ {path_id}")
            print(f"{'='*60}")
            
            # æ‰§è¡Œæµé‡æ‰«æå®éªŒ
            experiment_results = checker.traffic_sweep_experiment(
                network_config,
                path_to_vary=path_id,
                traffic_range=(args.traffic_min, args.traffic_max),
                num_points=args.num_points
            )
            
            # éªŒè¯ç‰©ç†æ„ä¹‰
            validation_results = checker.validate_physical_intuition(
                experiment_results, 
                network_config, 
                path_id, 
                args.output_dir
            )
            
            overall_results[f'path_{path_id}'] = validation_results
        
        # è®¡ç®—æ€»ä½“ç»“æœ
        overall_score = np.mean([
            results['pc_score'] 
            for results in overall_results.values()
        ])
        
        print(f"\n{'='*60}")
        print("æ€»ä½“éªŒè¯ç»“æœ")
        print(f"{'='*60}")
        print(f"æ¨¡å‹ç±»å‹: Original RouteNet (TF1.x)")
        print(f"æ€»ä½“PC-Scoreå¾—åˆ†: {overall_score:.4f}")
        
        if overall_score >= 0.7:
            print("âœ… åŸç‰ˆRouteNetæ¢¯åº¦è®¡ç®—é€šè¿‡PC-Scoreç‰©ç†ä¸€è‡´æ€§éªŒè¯ï¼")
        else:
            print("âŒ åŸç‰ˆRouteNetæ¢¯åº¦è®¡ç®—æœªé€šè¿‡PC-ScoreéªŒè¯ï¼Œéœ€è¦æ£€æŸ¥å®ç°")
        
        print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {args.output_dir}")
        
    except Exception as e:
        print(f"éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if 'checker' in locals():
            checker.close()

if __name__ == '__main__':
    main()
