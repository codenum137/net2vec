#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RouteNet TF2 ç»¼åˆæ¨¡å‹è¯„ä¼°è„šæœ¬
æ”¯æŒè¯„ä¼°delay/jitterå’Œdropsä¸¤ç§ä¸åŒçš„æ¨¡å‹ï¼Œå¹¶ç»˜åˆ¶ç›¸å¯¹è¯¯å·®CDFå›¾
æ”¯æŒåŒæ‹“æ‰‘ï¼ˆnsfnetï¼‰å’Œè·¨æ‹“æ‰‘ï¼ˆgbnï¼‰è¯„ä¼°
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import argparse
import os
from tqdm import tqdm
import seaborn as sns
import importlib
import re

# ä¸ºä¸åŒ TF ç‰ˆæœ¬é€‰æ‹©åç«¯æ¨¡å—ï¼ˆroutenet_tf2 æˆ– routenet_tf2_9ï¼‰
# åœ¨ main ä¸­æ ¹æ® --tf-compat å‚æ•°ä¸ TF ç‰ˆæœ¬æ£€æµ‹è£…é…ä»¥ä¸‹å…¨å±€ç¬¦å·ï¼š
# RouteNet, create_dataset, scale_fn, heteroscedastic_loss, binomial_loss, create_model_and_loss_fn
RouteNet = None
create_dataset = None
scale_fn = None
heteroscedastic_loss = None
binomial_loss = None
create_model_and_loss_fn = None

def _select_backend_module(tf_version: str, override: str) -> str:
    """æ ¹æ® TF ç‰ˆæœ¬æˆ–è¦†ç›–å‚æ•°é€‰æ‹©åç«¯æ¨¡å—åã€‚"""
    # å¤„ç†è¦†ç›–
    if override == 'tf2':
        return 'routenet_tf2'
    if override == 'tf2_9':
        return 'routenet_tf2_9'
    # è‡ªåŠ¨åˆ¤æ–­
    if not tf_version:
        return 'routenet_tf2'
    m = re.match(r'^(\d+)\.(\d+)', tf_version)
    if not m:
        return 'routenet_tf2'
    major = int(m.group(1))
    minor = int(m.group(2))
    if major < 2:
        return 'routenet_tf2_9'
    if major == 2 and minor <= 9:
        return 'routenet_tf2_9'
    return 'routenet_tf2'

def _wire_backend(tf_compat: str):
    """æ ¹æ®é€‰æ‹©è£…é…å…¨å±€ç¬¦å·ã€‚"""
    global RouteNet, create_dataset, scale_fn, heteroscedastic_loss, binomial_loss, create_model_and_loss_fn
    # å…è®¸ä»åŒç›®å½•å¯¼å…¥
    import sys as _sys
    _sys.path.append(os.path.dirname(__file__))
    tf_ver = getattr(tf, '__version__', None)
    module_name = _select_backend_module(tf_ver, tf_compat)
    mod = importlib.import_module(module_name)
    RouteNet = getattr(mod, 'RouteNet')
    create_dataset = getattr(mod, 'create_dataset')
    scale_fn = getattr(mod, 'scale_fn')
    heteroscedastic_loss = getattr(mod, 'heteroscedastic_loss')
    binomial_loss = getattr(mod, 'binomial_loss')
    create_model_and_loss_fn = getattr(mod, 'create_model_and_loss_fn')
    print(f"ğŸ”§ TF version: {tf_ver}; evaluate backend: {module_name}")

def load_model(model_dir, target, config, use_kan=False):
    """
    åŠ è½½æŒ‡å®šç›®æ ‡çš„æ¨¡å‹
    
    Args:
        model_dir: æ¨¡å‹ç›®å½•è·¯å¾„
        target: 'delay' æˆ– 'drops'
        config: æ¨¡å‹é…ç½®
        use_kan: æ˜¯å¦ä½¿ç”¨KANæ¨¡å‹
    
    Returns:
        model: åŠ è½½äº†æƒé‡çš„æ¨¡å‹
    """
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ–°çš„PhysicsInformedRouteNetæ¨¡å‹
    # é€šè¿‡æ£€æŸ¥æƒé‡æ–‡ä»¶åæ¥åˆ¤æ–­
    weight_files = []
    if use_kan:
        weight_files = [
            os.path.join(model_dir, "best_{}_kan_model.weights.h5".format(target)),
            os.path.join(model_dir, "best_kan_model.weights.h5"),
            os.path.join(model_dir, "best_{}_model.weights.h5".format(target)),
            os.path.join(model_dir, "best_model.weights.h5"),
            os.path.join(model_dir, "model.weights.h5")
        ]
    else:
        weight_files = [
            os.path.join(model_dir, "best_{}_model.weights.h5".format(target)),
            os.path.join(model_dir, "best_model.weights.h5"),
            os.path.join(model_dir, "model.weights.h5")
        ]
    
    weight_path = None
    for path in weight_files:
        if os.path.exists(path):
            weight_path = path
            break
    
    if weight_path is None:
        raise FileNotFoundError("No model weights found in {}".format(model_dir))
    
    # ç®€åŒ–ï¼šä»…ä½¿ç”¨æ ‡å‡†æ¨¡å‹åˆ›å»ºæ–¹å¼ï¼ˆMLP æˆ– KANï¼ŒåŒ…æ‹¬ B-splineï¼‰
    model, _ = create_model_and_loss_fn(config, target, use_kan=use_kan)
    model_type = "KAN" if use_kan else "MLP"
    kb = config.get('kan_basis', 'poly') if use_kan else None
    if use_kan and kb == 'bspline':
        print(f"Using KAN (bspline) for {target} evaluation")
    elif use_kan:
        print(f"Using KAN (poly) for {target} evaluation")
    else:
        print(f"Using MLP for {target} evaluation")
    print("Loading {} {} model weights from: {}".format(model_type, target, weight_path))
    return model, weight_path

def evaluate_delay_jitter_model(model, dataset, num_samples=None):
    """
    è¯„ä¼°å»¶è¿Ÿ/æŠ–åŠ¨é¢„æµ‹æ¨¡å‹
    
    Args:
        model: å»¶è¿Ÿé¢„æµ‹æ¨¡å‹ (è¾“å‡º2ç»´: [loc, scale])
        dataset: æµ‹è¯•æ•°æ®é›†
        num_samples: é™åˆ¶è¯„ä¼°çš„æ ·æœ¬æ•°é‡
    
    Returns:
        predictions: é¢„æµ‹ç»“æœ
        ground_truth: çœŸå®å€¼
        relative_errors: ç›¸å¯¹è¯¯å·®
    """
    predictions = {'delay': [], 'jitter': []}
    ground_truth = {'delay': [], 'jitter': []}
    
    sample_count = 0
    
    for features, labels in tqdm(dataset, desc="Evaluating delay/jitter model"):
        # æ¨¡å‹é¢„æµ‹ - å¼‚æ–¹å·®è¾“å‡ºï¼š[loc, scale]
        pred = model(features, training=False)
        
        pred_delay = pred[:, 0].numpy()  # å»¶è¿Ÿé¢„æµ‹å‡å€¼ (loc)
        
        # ä¸åŸç‰ˆä¿æŒä¸€è‡´çš„scaleè®¡ç®—ï¼ŒåŒ…å«cåç§»å¸¸æ•°
        c = np.log(np.expm1(np.float32(0.098)))
        pred_scale = tf.nn.softplus(c + pred[:, 1]).numpy() + 1e-9
        
        # æ ¹æ®åŸç‰ˆçš„å®ç°ï¼šjitter_prediction = scale**2
        pred_jitter = pred_scale ** 2
        
        # æ”¶é›†çœŸå®å€¼
        true_delay = labels['delay'].numpy()
        true_jitter = labels['jitter'].numpy()
        
        # å­˜å‚¨ç»“æœ
        predictions['delay'].extend(pred_delay)
        predictions['jitter'].extend(pred_jitter)
        
        ground_truth['delay'].extend(true_delay)
        ground_truth['jitter'].extend(true_jitter)
        
        sample_count += len(pred_delay)
        if num_samples and sample_count >= num_samples:
            break
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    for key in predictions:
        predictions[key] = np.array(predictions[key])
        ground_truth[key] = np.array(ground_truth[key])
    
    # è®¡ç®—ç›¸å¯¹è¯¯å·®
    relative_errors = {}
    for key in predictions:
        mask = np.abs(ground_truth[key]) > 1e-10
        rel_error = np.full_like(predictions[key], np.nan)
        rel_error[mask] = (predictions[key][mask] - ground_truth[key][mask]) / ground_truth[key][mask]
        relative_errors[key] = rel_error[~np.isnan(rel_error)]
    
    return predictions, ground_truth, relative_errors

def evaluate_drops_model(model, dataset, num_samples=None):
    """
    è¯„ä¼°ä¸¢åŒ…é¢„æµ‹æ¨¡å‹
    
    Args:
        model: ä¸¢åŒ…é¢„æµ‹æ¨¡å‹ (è¾“å‡º1ç»´: logits)
        dataset: æµ‹è¯•æ•°æ®é›†  
        num_samples: é™åˆ¶è¯„ä¼°çš„æ ·æœ¬æ•°é‡
    
    Returns:
        predictions: é¢„æµ‹ç»“æœ
        ground_truth: çœŸå®å€¼
        relative_errors: ç›¸å¯¹è¯¯å·®
    """
    predictions = {'drops': []}
    ground_truth = {'drops': []}
    
    sample_count = 0
    
    for features, labels in tqdm(dataset, desc="Evaluating drops model"):
        # æ¨¡å‹é¢„æµ‹ - è¾“å‡º logits
        pred_logits = model(features, training=False)
        pred_probs = tf.nn.sigmoid(pred_logits[:, 0]).numpy()
        
        # æ”¶é›†çœŸå®å€¼
        true_drops = labels['drops'].numpy()
        true_packets = labels['packets'].numpy()
        
        # è®¡ç®—çœŸå®ä¸¢åŒ…ç‡å’Œé¢„æµ‹ä¸¢åŒ…ç‡
        true_drop_rates = true_drops / (true_packets + 1e-10)  # é¿å…é™¤é›¶
        pred_drop_rates = pred_probs  # sigmoidè¾“å‡ºæœ¬èº«å°±æ˜¯æ¦‚ç‡/ä¸¢åŒ…ç‡
        
        # å­˜å‚¨ç»“æœ
        predictions['drops'].extend(pred_drop_rates)
        ground_truth['drops'].extend(true_drop_rates)
        
        sample_count += len(pred_drop_rates)
        if num_samples and sample_count >= num_samples:
            break
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    for key in predictions:
        predictions[key] = np.array(predictions[key])
        ground_truth[key] = np.array(ground_truth[key])
    
    # è®¡ç®—ç›¸å¯¹è¯¯å·®
    relative_errors = {}
    for key in predictions:
        # å¯¹äºä¸¢åŒ…ç‡ï¼Œåªæœ‰å½“çœŸå®ä¸¢åŒ…ç‡å¤§äºæŸä¸ªé˜ˆå€¼æ—¶æ‰è®¡ç®—ç›¸å¯¹è¯¯å·®
        # å› ä¸ºä¸¢åŒ…ç‡å¾ˆå°æ—¶ï¼Œç›¸å¯¹è¯¯å·®ä¼šéå¸¸å¤§
        mask = ground_truth[key] > 1e-6  # åªè€ƒè™‘ä¸¢åŒ…ç‡å¤§äº0.0001%çš„æƒ…å†µ
        rel_error = np.full_like(predictions[key], np.nan)
        rel_error[mask] = (predictions[key][mask] - ground_truth[key][mask]) / ground_truth[key][mask]
        relative_errors[key] = rel_error[~np.isnan(rel_error)]
    
    return predictions, ground_truth, relative_errors


def plot_linear_focus_cdf(nsfnet_errors, gbn_errors, output_dir, model_suffix=""):
    """
    ç»˜åˆ¶çº¿æ€§åˆ»åº¦çš„ç›¸å¯¹è¯¯å·®CDFå›¾ï¼Œæ˜¾ç¤ºæ­£è´Ÿè¯¯å·®åˆ†å¸ƒ
    
    Args:
        nsfnet_errors: nsfnetæ‹“æ‰‘çš„ç›¸å¯¹è¯¯å·®
        gbn_errors: gbnæ‹“æ‰‘çš„ç›¸å¯¹è¯¯å·®  
        output_dir: ä¿å­˜ç›®å½•
        model_suffix: æ¨¡å‹åç¼€ï¼ˆå¦‚"_kan"ç”¨äºåŒºåˆ†ä¸åŒæ¨¡å‹ç±»å‹ï¼‰
    """
    # è®¾ç½®é¢œè‰²å’Œçº¿å‹
    colors = {'delay': '#1f77b4', 'jitter': '#ff7f0e', 'drops': '#2ca02c'}
    linestyles = {'nsfnet': '-', 'gbn': '--'}
    
    plt.figure(figsize=(12, 8))
    
    for metric in ['delay', 'jitter']:
        if metric in nsfnet_errors and len(nsfnet_errors[metric]) > 0:
            sorted_errors = np.sort(nsfnet_errors[metric])
            cdf_values = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)
            plt.plot(sorted_errors, cdf_values, 
                    color=colors[metric], linestyle=linestyles['nsfnet'],
                    linewidth=2.5, label='NSFNet {}'.format(metric.upper()))
        
        if metric in gbn_errors and len(gbn_errors[metric]) > 0:
            sorted_errors = np.sort(gbn_errors[metric])
            cdf_values = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)
            plt.plot(sorted_errors, cdf_values,
                    color=colors[metric], linestyle=linestyles['gbn'],
                    linewidth=2.5, label='GBN {}'.format(metric.upper()))
    
    # æ·»åŠ ç†æƒ³æƒ…å†µçš„å‚è€ƒçº¿
    plt.axvline(x=0, color='red', linestyle=':', linewidth=3, alpha=0.8, label='Ideal (Zero Error)')
    
    # æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´æ ‡é¢˜
    model_type = "KAN" if "kan" in model_suffix.lower() else "MLP"
    title = 'Relative Error CDF - {} Model - Linear Scale with Positive/Negative Errors\\n(Ideal is Vertical Red Line at 0)'.format(model_type)
    
    plt.xlabel('Relative Error (Positive: Over-prediction, Negative: Under-prediction)', fontsize=14)
    plt.ylabel('CDF', fontsize=14)
    plt.title(title, fontsize=16)
    plt.grid(True, alpha=0.3)
    plt.legend(loc='center right', fontsize=12)
    
    # æ”¶é›†æ‰€æœ‰è¯¯å·®ï¼ˆåŒ…æ‹¬æ­£è´Ÿå€¼ï¼‰æ¥è®¾ç½®xè½´èŒƒå›´
    all_signed_errors = []
    for errors_dict in [nsfnet_errors, gbn_errors]:
        for metric in ['delay', 'jitter']:
            if metric in errors_dict and len(errors_dict[metric]) > 0:
                all_signed_errors.extend(errors_dict[metric])
    
    if all_signed_errors:
        min_error = np.min(all_signed_errors)
        max_error = np.max(all_signed_errors)
        # ä½¿ç”¨å¯¹ç§°çš„èŒƒå›´ï¼Œä»¥0ä¸ºä¸­å¿ƒ
        max_abs_error = max(abs(min_error), abs(max_error))
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…ï¼Œå¹¶ç¡®ä¿æ˜¾ç¤ºè´Ÿå€¼éƒ¨åˆ†
        display_range = min(max_abs_error * 1.2, 1.0)
        plt.xlim(-display_range, display_range)
    else:
        plt.xlim(-0.5, 0.5)
    plt.ylim(0, 1)
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…å«æ­£è´Ÿè¯¯å·®çš„ä¿¡æ¯
    detailed_stats = []
    for topo in ['nsfnet', 'gbn']:
        errors = nsfnet_errors if topo == 'nsfnet' else gbn_errors
        for metric in ['delay', 'jitter']:
            if metric in errors and len(errors[metric]) > 0:
                mean_error = np.mean(errors[metric])
                abs_errors = np.abs(errors[metric])
                median_abs_error = np.median(abs_errors)
                detailed_stats.append('{} {}: Mean={:.4f}, |Med|={:.4f}\n'.format(
                    topo.upper(), metric.upper(), mean_error, median_abs_error))
    
    detailed_stats_str = '\\n'.join(detailed_stats)
    plt.text(0.02, 0.98, detailed_stats_str, transform=plt.gca().transAxes, 
             fontsize=10, verticalalignment='top', 
             bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))
    
    # æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´æ–‡ä»¶å
    filename = 'relative_error_cdf{}.png'.format(model_suffix)
    output_path = os.path.join(output_dir, filename)
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.show()
    print("Linear scale CDF plot with positive/negative errors saved to: {}".format(output_path))

def print_evaluation_summary(nsfnet_errors, gbn_errors):
    """
    æ‰“å°è¯„ä¼°æ‘˜è¦ç»Ÿè®¡
    """
    print("\n" + "="*60)
    print("EVALUATION SUMMARY")
    print("="*60)
    
    for topo_name, errors in [('NSFNet (Same Topology)', nsfnet_errors), ('GBN (Different Topology)', gbn_errors)]:
        print("\n{}:".format(topo_name))
        print("-" * 40)
        
        for metric in ['delay', 'jitter']:
            if metric in errors and len(errors[metric]) > 0:
                abs_errors = np.abs(errors[metric])
                print("  {}: {} samples".format(metric.upper(), len(abs_errors)))
                print("    Mean Abs Error: {:.4f}".format(np.mean(abs_errors)))
                print("    Median Abs Error: {:.4f}".format(np.median(abs_errors)))
                print("    P90 Abs Error: {:.4f}".format(np.percentile(abs_errors, 90)))
                print("    P95 Abs Error: {:.4f}".format(np.percentile(abs_errors, 95)))
            else:
                print("  {}: No data available".format(metric.upper()))

def main():
    parser = argparse.ArgumentParser(description='Comprehensive RouteNet Evaluation')
    parser.add_argument('--delay_model_dir', type=str, required=True,
                      help='Directory containing delay prediction model')
    parser.add_argument('--nsfnet_test_dir', type=str, required=True,
                      help='Directory containing NSFNet test data')
    parser.add_argument('--gbn_test_dir', type=str, required=True,
                      help='Directory containing GBN test data')
    parser.add_argument('--output_dir', type=str, required=True,
                      help='Directory to save evaluation results')
    parser.add_argument('--batch_size', type=int, default=32,
                      help='Batch size for evaluation')
    parser.add_argument('--num_samples', type=int, default=None,
                      help='Limit number of samples to evaluate')
    parser.add_argument('--kan', action='store_true',
                      help='Evaluate KAN-based models instead of traditional MLP models')
    # KAN basis options (optional; only used when --kan is set)
    parser.add_argument('--kan_basis', type=str, choices=['poly', 'bspline'], default=None,
                      help='KAN basis type for readout: poly (default) or bspline')
    parser.add_argument('--kan_grid_size', type=int, default=None,
                      help='Number of intervals for B-spline grid (only for bspline basis)')
    parser.add_argument('--kan_spline_order', type=int, default=None,
                      help='Degree/order of B-spline basis (only for bspline basis)')
    # TF ç‰ˆæœ¬å…¼å®¹
    parser.add_argument('--tf-compat', choices=['auto', 'tf2', 'tf2_9'], default='auto',
                      help='Select evaluation backend by TF version: auto (default), tf2, tf2_9')
    
    args = parser.parse_args()

    # æŒ‰ç‰ˆæœ¬è£…é…åç«¯ï¼ˆé‡è¦ï¼šåœ¨ä½¿ç”¨ RouteNet/create_dataset å‰è°ƒç”¨ï¼‰
    _wire_backend(args.tf_compat)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # æ¨¡å‹é…ç½®ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
    config = {
        'link_state_dim': 4,
        'path_state_dim': 2,
        'T': 3,
        'readout_units': 8,
        'readout_layers': 2,
        'l2': 0.1,
        'l2_2': 0.01,
    }
    # If evaluating KAN models, wire optional basis config
    if args.kan:
        # try to infer bspline from model dir when not explicitly provided
        inferred_basis = None
        if args.kan_basis is None:
            mdl = args.delay_model_dir.lower()
            if 'bspline' in mdl or 'b_spline' in mdl or 'b-spline' in mdl:
                inferred_basis = 'bspline'
        basis = args.kan_basis or inferred_basis or 'poly'
        config['kan_basis'] = basis
        if basis == 'bspline':
            if args.kan_grid_size is not None:
                config['kan_grid_size'] = args.kan_grid_size
            if args.kan_spline_order is not None:
                config['kan_spline_order'] = args.kan_spline_order
    
    model_type = "KAN" if args.kan else "MLP"
    # Build a readable model description
    if args.kan:
        kb = config.get('kan_basis', 'poly')
        if kb == 'bspline':
            msg_extra = f" (basis=bspline, grid={config.get('kan_grid_size', 5)}, order={config.get('kan_spline_order', 3)})"
        else:
            msg_extra = " (basis=poly)"
    else:
        msg_extra = ""
    print("Starting comprehensive RouteNet evaluation with {} models{}...".format(model_type, msg_extra))
    print("Delay model dir: {}".format(args.delay_model_dir))
    print("NSFNet test dir: {}".format(args.nsfnet_test_dir))
    print("GBN test dir: {}".format(args.gbn_test_dir))
    
    # åŠ è½½æ¨¡å‹
    delay_model, delay_weight_path = load_model(args.delay_model_dir, 'delay', config, use_kan=args.kan)
    
    # åˆ›å»ºæ•°æ®é›†
    nsfnet_files = tf.io.gfile.glob(os.path.join(args.nsfnet_test_dir, '*.tfrecords'))
    gbn_files = tf.io.gfile.glob(os.path.join(args.gbn_test_dir, '*.tfrecords'))
    
    nsfnet_dataset = create_dataset(nsfnet_files, args.batch_size, is_training=False)
    gbn_dataset = create_dataset(gbn_files, args.batch_size, is_training=False)
    
    print("Found {} NSFNet test files".format(len(nsfnet_files)))
    print("Found {} GBN test files".format(len(gbn_files)))
    
    # åˆå§‹åŒ–æ¨¡å‹æƒé‡ï¼ˆéœ€è¦å…ˆè¿è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­ï¼‰
    print("\nInitializing models...")
    
    # è¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­ä»¥æ„å»ºæ¨¡å‹
    for dataset in [nsfnet_dataset.take(1)]:
        for features, labels in dataset:
            _ = delay_model(features, training=False)
            break
    
    # åŠ è½½æƒé‡
    delay_model.load_weights(delay_weight_path)
    print("Model loaded successfully!")
    
    # è¯„ä¼°NSFNetï¼ˆåŒæ‹“æ‰‘ï¼‰
    print("\n" + "="*50)
    print("EVALUATING NSFNET (SAME TOPOLOGY)")
    print("="*50)
    
    # è¯„ä¼°delayå’Œjitter
    _, _, nsfnet_delay_jitter_errors = evaluate_delay_jitter_model(
        delay_model, nsfnet_dataset, args.num_samples
    )
    nsfnet_errors = nsfnet_delay_jitter_errors
    
    # è¯„ä¼°GBNï¼ˆè·¨æ‹“æ‰‘ï¼‰
    print("\n" + "="*50)
    print("EVALUATING GBN (DIFFERENT TOPOLOGY)")
    print("="*50)
    
    # è¯„ä¼°delayå’Œjitter
    _, _, gbn_delay_jitter_errors = evaluate_delay_jitter_model(
        delay_model, gbn_dataset, args.num_samples
    )
    gbn_errors = gbn_delay_jitter_errors
    
    # æ‰“å°è¯„ä¼°æ‘˜è¦
    print_evaluation_summary(nsfnet_errors, gbn_errors)
    
    # ç»˜åˆ¶çº¿æ€§åˆ»åº¦CDFå›¾ï¼ˆä»…ç”Ÿæˆlinear_focusç‰ˆæœ¬ï¼‰
    print("\nGenerating linear focus CDF plot...")
    model_suffix = "_kan" if args.kan else "_mlp"
    plot_linear_focus_cdf(nsfnet_errors, gbn_errors, args.output_dir, model_suffix)
    
    print("\nEvaluation completed! Results saved to: {}".format(args.output_dir))

if __name__ == '__main__':
    main()
