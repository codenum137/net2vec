Extended results and code explanation supporting paper *Message-Passing Neural Networks Learn Little's Law* by Krzysztof Rusek and Piotr Chołda are avalable  in the notebook  [LittlesLaw](../jupyter_notebooks/LittlesLaw.ipynb).
In [graph_nn.py](graph_nn.py) we provide a TensorFlow implementation of neural message passing architecture described in the paper.
TensorFlow 2.0 port of this code is in [graph_nn2.py](graph_nn2.py)


**If you decide to apply the concepts presented or base on the provided code, please do refer our paper: K. Rusek and P. Chołda, "Message-Passing Neural Networks Learn Little’s Law," in IEEE Communications Letters. doi: 10.1109/LCOMM.2018.2886259.**

```
@ARTICLE{8572801, 
author={K. {Rusek} and P. {Chołda}}, 
journal={IEEE Communications Letters}, 
title={Message-Passing Neural Networks Learn Little’s Law}, 
year={2019}, 
volume={23}, 
number={2}, 
pages={274-277}, 
keywords={Delays;Neural networks;Topology;Routing;Network topology;Tools;Machine learning;Knowledge plane;machine learning;message-passing neural networks (MPNN);queuing networks;random graphs}, 
doi={10.1109/LCOMM.2018.2886259}, 
ISSN={1089-7798}, 
month={Feb},}
```